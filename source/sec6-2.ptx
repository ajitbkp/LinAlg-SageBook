<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec6-2" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Orthogonal Complements</title>
<introduction>
  <p>
    In this section, we shall explore the notion of orthogonal complement of 
    a subspace in a <m>\mathbb{R}^n</m>.
  </p>
</introduction>
  <subsection xml:id="subsec-orthogonal-complements">
    <title>Orthogonal Complements</title>
  <definition xml:id="def-orthogonal-complement">
    <statement>
      <p>
        Let <m>U\subset \R^n</m>. Then <m>U^\perp:=\{x\in \R^n: x\cdot u=0, \forall u\in U\}</m> 
        is called the <em>orthogonal complement</em> of <m>U</m>.
      </p>
    </statement>
  </definition>
  
  <exercise>
    <statement>
      <p>
        <ol marker="(i)">
          <li>
            <p>
              <m>\{0\}^\perp = \R^n</m>
            </p>
          </li>
          <li>
            <p>
              <m>{\R^n}^{\perp}=\{0\}</m>.
            </p>
          </li>
          <li>
            <p>
              Let <m>U\subset \R^n</m>. Then <m>U^\perp</m> is a subspace of <m>\R^n</m>. 
              Note that <m>U</m> need not be a subspace of <m>\R^n</m>.
            </p>
          </li>
        </ol>
      </p>
    </statement>
  </exercise>

  <example>
    <statement>
      <p>
        Let <m>U={\rm span}(\{(2,-1,1),(1,2,-1)\})</m>.
        Then
        <md>
          <mrow>U^\perp  =\amp  \{(x_1,x_2,x_3): 2x_1-x_2+x_3=0,x_1+2x_2-x_3=0\}</mrow>
          <mrow> =\amp {\rm null}\left(\begin{array}{rrr} 2 \amp  -1 \amp  1 \\ 1 \amp  2 \amp  -1 \end{array} \right)= \{t(1,-3,-5):t\in \R\}</mrow>
        </md>.
      </p>
    </statement>
  </example>

  <example>
    <statement>
      <p>
        Find the orthogonal complement of <m>span(\{\left(2,\,0,\,1,\,-1\right), \left(1,\,2,\,0,\,-1\right)\})</m>.
        <md>
          <mrow>U^\perp  =\amp  \{(x_1,x_2,x_3,x_3): 2x_1+x_3-x_4=0,x_1+2x_2-x_4=0\}</mrow>
          <mrow> =\amp {\rm null}\left(\begin{array}{rrrr} 2 \amp  0 \amp  1 \amp  -1 \\ 1 \amp  2 \amp  0 \amp  -1 \end{array} \right)</mrow>
          <mrow> =\amp  {\rm span}(\{(1,  0, -1,  1),(0,  1,  2,  2)\})</mrow>
        </md>
      </p>
    </statement>
  </example>

  <definition xml:id="subspace-projection1">
    <statement>
      <p>
        Let <m>U</m> be a subspace of <m>\R^n</m> with an orthogonal basis <m>\{u_1,\ldots,u_k\}</m>.
        If <m>x\in \R^n</m>, then
        <men xml:id="proj_onto_subspace">
          \proj_U(x)=\frac{x\cdot u_1}{\norm{u_1}^2}u_1+\frac{x\cdot u_2}{\norm{u_2}^2}u_2+\cdots + \frac{x\cdot u_k}{\norm{u_k}^2}u_k
        </men>.
        <m>\proj_U(x)</m> called the <em>orthogononal projection </em> of <m>x</m>  onto <m>U</m>.
      </p>
    </statement>
  </definition>

  <exercise>
    <statement>
      <p>
        Let <m>U</m> be a subspace of <m>\R^n</m> and <m>p=\proj_U(x)</m>.
        Then
      </p>
      <p>
        (i) <m>p\in U</m> and <m>(x-p) \in U^\perp</m>.
      </p>
      <p>
        (ii) <m>p</m> is a vector in <m>U</m>,
        which is closet to <m>x</m>.
        That is for all <m>y\in U</m>,
        <me>\norm{x-p}\leq \norm{x-y}</me>.
      </p>
    </statement>
    <hint>
      <p>
        
        Note that <m>(x-p)\perp (y-p)</m>.
        Hence by the Pythagoras theorem,
        <m>\norm{x-p}^2+\norm{p-y}^2=\norm{x-y}^2</m>.
        <me>
          \norm{x-y}^2=\norm{x-p+p-y}^2=\norm{x-p}^2+\norm{y-p}^2\geq \norm{x-p}^2
        </me>.
      </p>
    </hint>
  </exercise>

   <theorem xml:id="thm-sec-6-3-10">
    <statement>
      <p>
        Let <m>W</m> be a subspace of <m>\R^n</m>. Then for <m>x\in \R^n</m>, there exist 
        unique <m>w\in W</m>  and <m>w'\in W^{\perp}</m> such that <m>x=w+w'</m>. 
      </p>
      <p>
        In particualar <m>\R^n=W+W^{\perp}</m>. Since <m>W\cap W^{\perp}=\{0\}</m>, we have 
        <m>\R^n=W\oplus W^{\perp}</m>, called the direct sum of <m>W</m> and <m>W^{\perp}</m>.
      </p>
      <p>
        Furthermore 
        <me>\dim{(W)}+\dim{(W^\perp)}=n.</me>
      </p>
    </statement>

    <proof>
      <p>
        Choose an orthonormal basis <m>\{w_1,\ldots,w_k\}</m>. Define <m>w={\rm proj}_W(x)</m>. Define 
        <m>w'=x-p</m>. We claim that <m>w'\in W^{\perp}</m>.  Hence 
        <m>x=w+w'</m>.
      </p>
      <p>
        Suppose <m>x=w+w'</m>  and also <m>x=w_1+w_1'</m>  such that <m>w,w_1\in W</m> and 
        <m>w',w_1'\in W^{\perp}</m>. Then <m>w-w_1=w'-w_1'</m>. This implies 
      <me>
        w-w_1,w'-w_1'\in W\cap W^{\perp}=\{0\}.
      </me>
      Hence we have <m>w=w_1</m> and <m>w'=w_1'</m>.
      </p>
    </proof>
  </theorem>
 
<exercise>
  <p>
    For any subspace <m>W</m> of <m>\R^n</m>, <m>{(W^\perp)}^{\perp}=W</m>. 
  </p>
  <hint>
    <p>
      Let <m>x\in W</m>, then for all <m>y\in W^\perp</m>, we have 
      <m>y^Tx=0</m>. That is <m>x\in {(W^\perp)}^{\perp}</m>. Hence <m>W\subset {(W^\perp)}^{\perp}</m>. 
      To show <m>W={(W^\perp)}^{\perp}</m>, it is enough to show 
      <m>\dim{(W)}=\dim{({(W^\perp)}^{\perp})}</m>. 
      <me>
        \dim{({(W^\perp)}^{\perp})}=n-\dim{(W^\perp)}=n-(n-\dim{(W)})=\dim{(W)}.
      </me>
    </p>
  </hint>
</exercise>
  <example>
    <statement>
      <p>
        Consider the plane <m>\pi=\{(x,y,z)\in \R^3:3x+y-5z=0\}</m>.
        It is easy to see that <m>v_1=(2,-1,1),
        v_2=(1,2,1)</m> lie on the plane <m>\pi</m>.
        Using the Gram-Schmidt process we can find an orthogonal basis <m>u_1 = (2,-1,1),
        u_2=(2/3, 13/6, 5/6)</m> on <m>\pi</m>.
        Let us find the orthogonal projection of <m>v=(1,2,3)</m> onto <m>\pi</m>.
        The required vector
        <me>
          \proj_\pi(v)=\frac{v\cdot u_1}{\norm{u_1}^2}u_1+\frac{v\cdot u_2}{\norm{u_2}^2}u_2=(13/7, 16/7, 11/7)
        </me>.
      </p>
    </statement>
  </example>

  <p> <term>Orthogonal Projection onto a subspace</term></p>

  <p>
    How to find the orthogonal projection of a vector on to the subspace spanned by a set of vectors in <m>\R^n</m>?
    Let <m>\beta = \{w_1,\ldots, w_k\}</m> be a basis of <m>W</m>.
    We want to find the vector <m>p</m> which is the orthogonal projection of <m>v</m> onto <m>W</m>.
  </p>

  <p>
    Note that <m>p\in W</m>, therefore,
    there exist scalars <m>x_1,\ldots, x_k</m> such that
    <me>
      p=x_1 v_1+\cdots + x_k v_k=Ax
    </me>
    where <m>A=[v_1~\cdots ~ v_k]</m> and <m>x=[x_1~\cdots~x_k]^T</m>.
  </p>

  <p>
    It is clear that <m>v-p=v-Ax\in W^\perp</m>.
    Hence <m>(v_i)^T(v-Ax)=0</m> for <m>1\leq i\leq k</m>.
    This is same as
    <me>
      A^T(v-Ax)=0 \implies x=(A^TA)^{-1}(A^Tv)
    </me>.
  </p>
  
  <p>
    Hence
    <men xml:id="orth-Proj-W">
      p=A(A^TA)^{-1}(A^Tv)
    </men>
  </p>
  <p>
    The matrix <m>Q=A(A^TA)^{-1}A^T</m> is called the
    <em>projection matrix</em> for the subspace <m>W</m>.
  </p>
  
  <example>
    <p>
      Consider a set of vectors
      <me>
        v_1 = \left(\begin{array}{r}
-1 \\
1 \\
0 \\
-3 \\
-3
\end{array}\right), v_2=\left(\begin{array}{r}
1 \\
-5 \\
3 \\
-1 \\
4
\end{array}\right), v_3 = \left(\begin{array}{r}
-5 \\
13 \\
-6 \\
-7 \\
-17
\end{array}\right), v_4 = \left(\begin{array}{r}
-2 \\
1 \\
3 \\
8 \\
1
\end{array}\right).
      </me>
    Let <m>W</m> be the subspace spanned by <m>\{v_1,v_2,v_3,v_4\}</m> in <m>\mathbb{R}^5</m>. Find the orthogonal projection of the vector <m>u = \left(\begin{array}{r}
1 \\
3 \\
5 \\
7 \\
11
\end{array}\right)</m> onto <m>W</m> in Sage.  
    </p>
    <solution>
      
        <sage>
      <input>
        v1 = vector(QQ,[-1, 1, 0, -3, -3])
v2 = vector(QQ,[1, -5, 3, -1, 4])
v3 = vector(QQ,[-5, 13, -6, -7, -17])
v4 = vector(QQ,[-2, 1, 3, 8, 1])
u = vector(QQ,[1,3,5,7,11])
A = column_matrix([v1,v2,v3,v4])
p = A.pivots()
p
      </input>
      <output>
        
      </output>
    </sage>
     <p> Since pivots indices are <m>\{0,1,3\}</m>, <m>v_1,v_2,v_4</m> are linearly independent. 
      We define a matrix <m>M</m> of whose columns are <m>v_1,v_2,v_4</m>. Then the orthogonal projection 
      of <m>u</m> onto <m>W</m> is <m>M(M^TM)^{-1}M^Tu</m>. 
     </p> 

     <sage>
      <input>
        L = [A.columns()[x] for x in p]
        M = column_matrix(L)
        p = M*(M.T*M).inverse()*M.T*u
        print('The orthogonal projection is:')
        print(p)
        print('The orthogonal projection matrix is:')
        P = M*(M.T*M).inverse()*M.T
        print(P)
      </input>
      <output>
        
      </output>
     </sage>
     <p> It is easy to check that <m>u-p</m>  is orgthogonal to <m>W</m>.</p>
      <sage>
        <input>
          print(v1.dot_product(u-p), v2.dot_product(u-p),v3.dot_product(u-p),v4.dot_product(u-p))
        </input>
        <output>
          
        </output>
      </sage>
    </solution>
  </example>
  <exercise>
    <statement>
      <p>
        Let <m>A</m> be an <m>n\times n</m> real matrix.  
        Recall <m>{\cal R}(A)</m> and <m>{\cal N}(A)</m>, range or columns space of <m>A</m> 
        and null or kernel of <m>A</m>. Then show that 
        <ol>
          <li>
            <p>
              <m>{\cal R}(A)^\perp={\cal N}(A^T)</m> or <m>{\rm Col}(A)^\perp = {\rm null}(A^T)</m>.
            </p>
          </li> 
          <li>
            <p>
              <m>{\rm Row}(A)^\perp = {\rm null}(A)</m>.
            </p>
          </li>
          <li>
            <p>
              <m>{\cal N}(A)^\perp={\cal R}(A^T)</m>.
            </p>
          </li>
          
        </ol>
      </p>
     <hint>
      <p>
          Let <m>x \in {\cal R}(A)^\perp</m>.  Then for <m>y\in \R^n</m>, <m>Ay\in {\cal R}(A)</m>. 
          Hence <m>0=(Ay)^Tx=y^TA^Tx</m>. This implies <m>A^Tx=0</m>. Hence <m>x\in {\cal N}(A^T)</m>. 
          That is, <m>{\cal R}(A)^\perp\subseteq {\cal N}(A^T)</m>. 
      </p>
      <p>
          Next let <m>x\in {\cal N}(A^T)</m> then <m>(Ay)^Tx=y^TA^Tx=0</m> for all <m>y</m>. 
          Hence <m>x\in {\cal R}(A)^\perp</m>. 
          That is, <m>{\cal N}(A^T) \subseteq {\cal R}(A)^\perp</m>. Hence 
          <m>{\cal R}(A)^\perp={\cal N}(A^T)</m>.
        </p>

        <p>
       Replacing <m>A</m> by <m>A^T</m>, in (1), we get
       <me>
        {{\cal R}(A^T)}^\perp={\cal N}(A).
       </me>
       Hence
       <me>
        {{\cal N}(A)}^\perp={{{\cal R}(A^T)}^\perp}^\perp={\cal R}(A^T).
       </me>
        </p>

        <p>
          We write rows of <m>A</m> and <m>r_1,\ldots r_m</m> and columns of <m>A</m> as 
          <m>a_1,\ldots a_n</m>. Then for any <m>x\ijn \R^n</m>, we have
          <me>
            Ax=x_1a_1+x_2a_2+\cdots+x_na_n=
            \begin{bmatrix} r_1\cdot x\\r_2\cdot a\\\vdots \\r_m\cdot x\end{bmatrix}. 
          </me>
          Hence if <m>Ax=0</m>, then <m>r_i\cdot x=0</m> for all <m>i</m>. This implies 
          <m>x\in {\rm Row}(A)^\perp</m>. That is <m>{\rm null}(A)\subset {\rm Row}(A)^\perp </m>. 
        </p>
        <p>
          If <m>y\in {\rm Row}(A)^\perp</m>, then <m>r_i\cdot y=0</m> for all <m>i</m>. Hence 
          <m>Ay=0</m>. This implies <m>y\in {\rm null}(A)</m>. That is, 
           <m>{\rm Row}(A)^\perp\subset {\rm null}(A)</m>. Hence 
            <m>{\rm Row}(A)^\perp = {\rm null}(A)</m>.
        </p>
      </hint>
     
    </statement>
  </exercise>

  
  </subsection>
  <subsection xml:id="subsec-Proj-Ref_HyperPlane">
    <title>Projection and Reflection</title>
    <introduction>
      <p>
        In this subsection, we deal with two concepts, orthogonla projection of a vector onto a hyperplane in <m>\mathbb{R}^n</m> and reflection of a vector about a hyperplane.
      </p>
    </introduction>

    <definition xml:id="def-hyperplane">
      <statement>
        <p>
        A hyperplane <m>H</m> in <m>\mathbb{R}^n</m> is an <m>n-1</m>-dimensional affine space defined by 
        <men xml:id="eqn-hyperplane">
          H:=\{x\in \mathbb{R}^n: a^x=b\}        
        </men>
        where <m>a</m> is a nonzero vector in <m>\mathbb{R}^n</m> and <m>b\in \mathbb{R}</m>. 
        If <m>b=0</m>, then <m>H</m> is an <m>n-1</m>-dimensiional subspace of of <m>\mathbb{R}^n</m>. 
        </p>
        
        <p>
         Note that if  <m>H</m> is an <m>n-1</m>-dimensiional subspace of of <m>\mathbb{R}^n</m>, defined by <m>a</m>, let us 
         denote it by <m>H_a</m>, then <m>a</m> is orthogonal to <m>H</m>. 
        </p>
      </statement>
    </definition>
<p>
    How to find the orthogonal projection of a vector <m>v\in \mathbb{R}^n</m> onto <m>H_a</m>? Note that we have already done one way 
    by finding a basis vector of <m>H_a</m>. We would like to get a formula in terms of <m>a</m>. If <m>v_{H_a}</m> is the orthogonal projection of <m>v</m> onto <m>H_a</m>, then it can be obianed by taking out the orthogonal prjection of <m>v</m> onto the vector <m>a</m>  from <m>v</m>. Thus we have
    <men xml:id="eqn-othgonal-proj1">
      v_{H_a} = v-\frac{v\cdot a}{\norm{a}^2}a=v-\frac{aa^T}{\norm{a}^2}v=(I-\frac{aa^T}{\norm{a}^2})v.
    </men>
    The matrix <m>P_H=(I-\frac{aa^T}{\norm{a}^2})</m> is nothing but the <em>projection matrix</em>.
  </p>
  <p>
    
  How do we obtain <m>v_H</m>, the orthogonal projection of <m>v</m> onto <m>H</m>? Note that <m>v-v_H</m> is parallel to <m>a</m>. Hence 
  <m>v-v_H=ta</m> for some scalar <m>t</m>. Since <m>v_H=v-ta\in H</m>, we have <m>a^T(v-ta)=b</m>. Simplyfying we get
    <men xml:id="eqn-othgonal-proj2">
      v_H = v-\frac{v\cdot a-b}{\norm{a}^2}a.
    </men>
  </p>  
  <sage>
    <input>
  def project_onto_hyperplane(a, b, x):
      """
      a, x : vectors (length d)
      b : scalar
      returns: projection of x onto { y : a^T y = b }
      """
      a = vector(RR, a)
      x = vector(RR, x)
      denom = a.dot_product(a)
      if denom == 0:
          raise ValueError("Normal vector a must be nonzero.")
      t = (a.dot_product(x) - b) / denom
      return x - t * a
    </input>
    <output>
      
    </output>
  </sage>

  <example xml:id="eg-orthogonal-proj-sage1">
   <statement>
    <p>
      Find the orthogonal projevction of a vector <m>(1,2,3,4)</m> to to the hyperplane given by <m>3x_1-2x_2+5x_3+4x_4=7</m> in <m>\mathbb{R}^4</m>
    </p>
   </statement>
   <p>
   <solution>
  
      <sage>
        <input>
a = vector([3, -2, 5, 4])
b = 7
x = vector([1,2,3,4])
xH = project_onto_hyperplane(a, b, x)
print("Projection x_H =", xH)
print("Check a^T x_H =", a.dot_product(xH), " (should equal b =", b, ")")
        </input>
        <output>
          
        </output>
      </sage>
   
   </solution> 
   </p>
  </example>
  <p>
    Next we wish to find the reflection of a vector <m>v</m> about the hyperplane <m>H</m>.  Suppose 
    <m>v_R</m> is the projection of <m>v</m> about <m>H</m>, then <m>v_R</m> can be obtained by going the same distance on the 
    opposite side along the vector <m>v-v_H</m>. Thus
    <men xml:id="eqn-othgonal-ref1">
      v_R = v_H-(v-v_H)=2v_H-v
    </men>
    
  Substituting the formula for <m>v_H</m>, and after simplification, we get
    <men xml:id="eqn-othgonal-ref2">
      v_R = v - 2 \frac{a^T v - b}{\norm{a}^2} a.
    </men>
   </p>
<p>
    As as special if <m>b = 0</m>, the hyperplane passes through the origin,
            <me>
                v_R = v - 2 \frac{a^T v}{\norm{a}^2} a=(I-2\frac{aa^T}{\norm{a}^2}v).
            </me>
    If <m>a</m> is a unit vector, <m>\|a\| = 1</m>, this simplifies to:
            <me>
                v_R = v - 2(a^T v) a=(I-2(aa^T))v.
            </me>
      The matrix <m>R_H =I-2\frac{aa^T}{\norm{a}^2}</m> is called the <em>reflection matrix</em>.
          </p>

  <sage><title>Sage Code for Reflection</title>
    <input>
# Reflection of a vector about a hyperplane in SageMath

def reflect_about_hyperplane(x, a, b):
    """
    Reflect vector x about the hyperplane aÂ·y = b.
    x, a: vectors in R^n
    b: scalar
    """
    # Ensure vectors are in Sage vector format
    x = vector(RR, x)
    a = vector(RR, a)
    
    # Check normal vector is nonzero
    if a.norm() == 0:
        raise ValueError("Normal vector 'a' must be nonzero.")
    
    # Reflection formula
    x_R = x - 2 * (a.dot_product(x) - b) / (a.norm()^2) * a
    return x_R     
    </input>
    <output>
      
    </output>
  </sage>
  <example> 
    <p>Find the reflection of the vector <m>x=(4,2,-1,3)</m> about the hyperplane <m>2x_1-x_2+3x_3+4x_4=5</m>.
<sage>
  <input>
a = [2, -1, 3,4]    # normal vector
b = 5             # hyperplane constant
x = [4, 2, -1,3]    # point to reflect
x_reflected = reflect_about_hyperplane(x, a, b)
print("Reflected vector:", x_reflected)

  </input>
  <output>
    
  </output>
</sage>
</p>
  </example>

  <activity>
    <em>Plottig orthogonal projection and reclection in <m>\mathbb{R}^3</m></em>
    <p> Use sage to plot the hyperplane <m>H</m> defined by the equation <m>3x-2y+z=2</m> and also plot the vector <m>v=(1,-1,3)</m> and its
    orthogonal projection <m>v_H</m> and the reflection <m>v_R</m> about <m>H</m>.
    </p>
  </activity>
  </subsection>

  <conclusion>
        <p>
            Orthogonal complements provide a way to decompose vector spaces and are closely related to projections and reflections.
        </p>
    </conclusion>
</section>
