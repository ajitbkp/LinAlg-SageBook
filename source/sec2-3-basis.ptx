<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec-2-3-basis-dimension" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Basis and Dimension</title>
<p>
<definition xml:id="def-sec2-2-LI"><title>Basis</title>


  <statement>
    <p>
      A set of vectors <m>\beta=\{v_1,v_2,\ldots,v_n\}</m> is called a basis of <m>\R^n</m> if every vector <m>v\in \R^n</m> can be  expressed uniquely as  linear combinations of <m>v_1,v_2,\ldots,v_n</m>. 
	
      Thus <m>\beta</m> is basis of <m>\R^n</m> if 
    <p>(i) <m>L(\beta)=\R^n</m>, that every vector <m>v\in \R^n</m> can be expressed as linear combinations of <m>v_1,v_2,\ldots,v_n</m>. </p>
    <p>	(ii) If <m>v=\alpha_1v_1+\alpha_2v_2+\cdots +\alpha_nv_n</m> and <m>v=\beta_1v_1+\beta_2v_2+\cdots +\beta_nv_n</m>, then <m>\alpha_1=\beta_1, \alpha_2=\beta_2=\cdots,\alpha_n=\beta_n</m>.</p>
    <p>
    Similarly one can define a basis of any subspace of <m>\R^n</m>.</p>     
    </p>
  </statement>
</definition>
</p>

<p>
  It is easy to prove the follwoing theorem which is opent taken as definition in many books.
</p>
<p>
  <theorem xml:id="thm-sec2-3-basis-thm1">
    <statement>
      <p>
        A set of vectors <m>\beta=\{v_1,v_2,\ldots,v_n\}</m> is called a basis of <m>\R^n</m> iff (i) <m>L(\beta)=\R^n</m>and <m>\beta</m> is linearly independent. 
    
      </p>
    </statement>
  </theorem> 
</p>
<p>
  <example>
    <p> (i) <m>\{(1,0),(0,1)\}</m> is a basis of <m>\R^2</m> called the standard basis of <m>\R^2</m>.</p>
    <p>  (ii) <m>\{(1,-1),(2,1)\}</m> is a basis of <m>\R^2</m>.</p>
    <p> (iii) <m>\{(1,0,0),(0,1,0),(0,0,1)\}</m> is a basis of <m>\R^3</m> called the standard basis of <m>\R^3</m>. </p>
    <p> (iv) <m>\{(1,1,-1),(-1,1,1),(1,-1,1)\}</m> is a basis of <m>\R^3</m>. </p>
      
  </example>
</p>
<p>
  In <m>\R^n</m>, we define <m> e_i:=(0,\ldots, 1,\ldots,0)</m> where <m>i</m> component is 1 rest are zeros. Then it is easy to see that <m> \{e_1,\ldots, e_n\}</m> is a bais of  <m>\R^n</m> called the <alert>standard basis</alert>.
</p>
<p>
<example>
  <p>
    Consider the plane <m>W=\{(x_1,x_2,x_3)\in \R^3:x_1+2x_2-x_3=0\}</m>. Note that, here <m>x_1</m> and <m>x_2</m> can be thought of as free variables. Any point <m>(x_1,x_2,x_3)\in W</m>, we have 
<me>(x_1,x_2,x_3)=(x_1,x_2,x_1+2x_2)=(\alpha,\beta,\alpha+2\beta)=\alpha(1,0,1)+\beta(0,1,2).</me>
Thus <m>\{(1,0,1),(0,1,2)\}</m> spans <m>W</m>. It is easy to see that <m>\{(1,0,1),(0,1,2)\}</m> is linearly independent. Hence <m>\beta =\{(1,0,1),(0,1,2)\}</m> is a basis of <m>W</m>. In fact, any two vectors in <m>W</m> which are linearly independent form a basis of <m>W</m>.


  </p>
</example>
</p>
<p>
  <theorem xml:id="thm-sec2-3-thm3">
    <statement>
      <p>
        Any set of <m>n</m> linearly independent vectors forms a basis of <m>\R^n</m>.

      </p>
    </statement>
  </theorem>
  
</p>
<p>
  <proof>
    <p>
      Follows from Theorem <xref ref="thm-sec2-2-thm2"/>.
    </p>
  </proof>
</p>

<p>
  <theorem xml:id="thm-sec2-3-thm4">
    <statement>
      <p>
     Let <m> \beta=\{v_1,v_2,\ldots,v_k\}</m> be a basis of a subscape <m>W</m>  of <m>\R^n</m> with <m>k</m> elements. Then any set 
     <m>S=\{v_1,v_2,\ldots, v_{k+1}\}\subset W</m> with <m>k+1</m> elements is linearly dependent.   
      </p>
    </statement>
  </theorem>
  </p>
 <p>
  <proof>
    <p>
      Let <m>\alpha_1,\ldots,\alpha_{k+1}</m> be scalars such that
      <men xml:id="sec2-3-eq1"> \alpha_1 v_1+\alpha_2v_2+\cdots+\alpha_kv_k+\alpha_{k+1}v_{k+1}=0</men>
      Since <m>\beta</m> is a basis of <m>W</m>, for each <m>i=1,2,\ldots, k+1</m>, we have
      <me> v_i = \sum_{j=1}^k a_{ij}u_j</me>
      Substituting this in Equation <xref ref="sec2-3-eq1"/>, we get
      <men xml:id="sec2-3-eq2">
        \alpha_1 \left(\sum_{j=1}^k a_{1j}u_j\right)+\cdots+
        \alpha_{k+1}\left(\sum_{j=1}^k a_{k+1j}u_j\right)=0
      </men>
      Collecting the coefficients of <m>u_i's</m> in the Equation <xref ref="sec2-3-eq2"/>, we get
    <men xml:id="sec2-3-eq3">
      \left(\sum \alpha_ia_{i1}\right)u_1+\cdots +
      \left(\sum \alpha_ia_{ik+1}\right)u_{k+1}=0.
    </men>
    Since<m>\beta</m> is lineary independent, we have
    <md>
      <mrow>\alpha_1 a_{11}+\alpha_2a_{21}+\cdots+\alpha_{k+1}a_{k+11} =\amp 0 </mrow>
      <mrow>\alpha_1 a_{12}+\alpha_2a_{22}+\cdots+\alpha_{k+1}a_{k+12} =\amp 0 </mrow>
      <mrow>\vdots  \amp  </mrow>
      <mrow>\alpha_1 a_{1k}+\alpha_2a_{2k}+\cdots+\alpha_{k+1}a_{k+1k} =\amp 0 </mrow>
    </md>
    </p>
    These are <m>k</m> homogeneous linear equations in <m>k+1</m> variables <m>\alpha_1,\ldots,\alpha_{k+1}</m>. 
      Hence it has a non zero solution. In particular, there exist scalars,  <m>\alpha_1,\ldots,\alpha_{k+1}</m> not all zero such that <m>\alpha_1 v_1+\alpha_2v_2+\cdots+\alpha_kv_k+\alpha_{k+1}v_{k+1}=0</m>. Hence <m>S</m> is linearly dependent.
  </proof>
</p>
  
<corollary xml:id="sec2-3-cor1">
  <statement>
    <p>
      Let <m> \beta=\{v_1,v_2,\ldots,v_k\}</m> be a basis of a subscape <m>W</m>  of <m>\R^n</m> with <m>k</m> elements. If <m>S</m> is a linearly independet subset in <m>W</m>, then <m>|S|\leq k</m>. 
    </p>
  </statement>
</corollary>
<p>
  <theorem xml:id="thm-sec2-3-thm5">
    <statement>
      <p>
        Let <m>\beta</m> and <m>\gamma</m> be two bases of  a subscape <m>W</m>  of <m>\R^n</m>. Then <m>\beta</m> and <m>\gamma</m> have the same number of elements. 
      </p>
    </statement>
  </theorem>
  </p>
  <p>
  <proof>
    <p>
      Suppose <m>|\beta|=r</m> and <m>|\gamma|=s</m>.  Since <m>\beta</m> is a basis and <m>\gamma</m> is linearly independet, by Corollary <xref ref="sec2-3-cor1"/>, <m>s\leq r</m>. Similarly <m>\gamma</m> is a basis and <m>\beta</m> is linearly independet, we have <m>s\leq r</m>. Hence <m>r=s</m>.
    </p>
  </proof>
</p>
Since the number of elements any two bases are same. This leads to the dinition of dimension of a vector subspace.

<p>
  <definition xml:id="def-sec2-3-dimension">
    <statement>
      <p>
        Let <m>W</m> be subspace of <m>\R^n</m>. The number of elements in a basis of <m>W</m> is called the <alert>dimension</alert> of <m>W</m>. 	
 
      </p>
    </statement>
  </definition>
</p>
<p>
  <example>
    <p>(i) <m>\R^n</m> is a <m>n</m>-dimensional vector space over <m>\R</m>.</p>
<p>(ii) Any plane passing through origin in <m>\R^3</m> is a 2 dimensional subspace.</p>
<p>(iii) <m>W:=\{(x_1,\ldots,x_n):x_1+\cdots+x_n=0\}</m> is <m>n-1</m> dimensional subspace of <m>\R^n</m>. Write down a basis of <m>W</m>.</p>
<p>(iv) <m>W=\{(x_1,x_2,x_3,x_4)\in \R^4:x_1=x_3,x_2=x_4\}</m> is a 2-dimensional subspace of <m>\R^4</m>. Write dowm a basis of <m>W</m>.</p>

  </example>
</p>
<p>
  <alert>How to find basis of a subspace?</alert>
  </p>
  <p>
  Suppose  <m>W</m> is subspace spanned by a set of <m>k</m> vectors, say, 
  <m>v_1,\ldots,v_k</m> in <m>\R^n</m>. How to find a basis of <m>W</m>? 
  Note that <m>\dim{(W)}\leq k</m>. In order to find a basis of <m>W</m>, 
  we construct a matrix <m>A</m> whose rows are <m>v_1, \ldots, v_k</m>. 
  Find the reduced-row-echelon form  of <m>A</m>. 
  Then the non-zero rows in RREF(<m>A</m>) form a basis of <m>W</m>.  
  </p>
  
  <p>
  <example>
 <p>         Consider the set of vectors <m>v_1 =\left(1,-1,2,3,1,4\right)</m>, <m>v_2=\left(2,1,0,2,-3,1\right)</m>, <m>v_3=\left(-4,-5,4,0,11,5\right)</m>, <m>v_4=\left(-1,0,2,1,3,2\right)</m> and <m>v_5=\left(-2,-2,4,2,7,5\right)</m>. Let <m>W</m> be the linear span of <m>\{v_1,v_2,v_3,v_4,v_5\}</m>. Let us find a basis and hence the dimension of <m>W</m>. 
 </p>

    <p>
            We construct the matrix <m>A</m> whose rows are <m>\{v_1,v_2,v_3,v_4,v_5\}</m> and apply RREF.
     
                <me>
                RREF\left(\left[\begin{array}{rrrrrr}
                  1 \amp  -1 \amp  2 \amp  3 \amp  1 \amp  4 \\
                  2 \amp  1 \amp  0 \amp  2 \amp  -3 \amp  1 \\
                  -4 \amp  -5 \amp  4 \amp  0 \amp  11 \amp  5 \\
                  -1 \amp  0 \amp  2 \amp  1 \amp  3 \amp  2 \\
                  -2 \amp  -2 \amp  4 \amp  2 \amp  7 \amp  5
                \end{array}\right]\right)=\left[\begin{array}{rrrrrr}
                1 \amp  0 \amp  0 \amp  1 \amp  -\frac{5}{4} \amp  \frac{3}{4} \\
                0 \amp  1 \amp  0 \amp  0 \amp  -\frac{1}{2} \amp  -\frac{1}{2} \\
                0 \amp  0 \amp  1 \amp  1 \amp  \frac{7}{8} \amp  \frac{11}{8} \\
                0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  0 \\
                0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  0
                \end{array}\right]</me>

           Thus <m>W</m> has a basis consisting of three non zero rows of <m>RREF(A)</m>. That is, 
              <me>\beta = \left\{\left(1 , 0 , 0 , 1 , -\frac{5}{4} , \frac{3}{4}\right),
              \left(0 , 1 , 0 , 0 , -\frac{1}{2} , -\frac{1}{2}\right),
              \left(0 , 0 , 1 , 1 , \frac{7}{8} , \frac{11}{8}\right)\right\}</me> is basis of <m>W</m> and it is a 3 dimensional subspace of <m>\R^6</m>.
              Note that <m>W</m> is also the row space of <m>A</m>.       
              
              <p>
              Note that each column of <m>A</m> is a vector in <m>\R^5</m>. Let us find the column space of <m>A</m>. Thus to find the <m>{\rm col}(A)</m>, we take the transpose of <m>A</m> and apply the RREF. 
              </p>
<me>
RREF\left(\left[\begin{array}{rrrrr}
	1 \amp  2 \amp  -4 \amp  -1 \amp  -2 \\
	-1 \amp  1 \amp  -5 \amp  0 \amp  -2 \\
	2 \amp  0 \amp  4 \amp  2 \amp  4 \\
	3 \amp  2 \amp  0 \amp  1 \amp  2 \\
	1 \amp  -3 \amp  11 \amp  3 \amp  7 \\
	4 \amp  1 \amp  5 \amp  2 \amp  5
\end{array}\right]\right)=
\left[\begin{array}{rrrrr}
	1 \amp  0 \amp  2 \amp  0 \amp  1 \\
	0 \amp  1 \amp  -3 \amp  0 \amp  -1 \\
	0 \amp  0 \amp  0 \amp  1 \amp  1 \\
	0 \amp  0 \amp  0 \amp  0 \amp  0 \\
	0 \amp  0 \amp  0 \amp  0 \amp  0 \\
	0 \amp  0 \amp  0 \amp  0 \amp  0
\end{array}\right]
</me>

Thus the basis <m>\gamma</m> of  <m>{\rm col}(A)</m> consists of three non-zero rows of <m>RREF(A^T)</m>. Thus 
<me>
\gamma=\{(1,0,2,0,1),(0,1,-3,0,-1),(0,0,0,1,1)\}
</me>
is a basis of <m>{\rm col}(A)</m>. Notice that <m>\dim{({\rm col}(A))}=\dim{({\rm row}(A))}</m>.
        </p>
      </example>
    </p>

    <p>
      <definition xml:id="def-row-column-rank">
        <statement>
          <p>
            The <m>\dim{({\rm col}(A))}</m> is called the <alert>column rank</alert> of <m>A</m> and <m>\dim{({\rm row}(A))}</m> is called the <alert>row rank </alert>of <m>A</m>.	    
          </p>
        </statement>
      </definition>
    </p>
    <p>
      <theorem xml:id="thm-row-rank-col-rank">
        <statement>
          <p>
            The row rank and column rank of any matrix are same. This is called the rank of the matrix.
          </p>
        </statement>
      </theorem>
      
    </p>

    <p>
      <example>
        Consider a matrix <m>A=\left[\begin{array}{rrrrr}
          1 \amp  2 \amp  -4 \amp  -1 \amp  -2 \\
          -1 \amp  1 \amp  -5 \amp  0 \amp  -2 \\
          2 \amp  0 \amp  4 \amp  2 \amp  4 \\
          3 \amp  2 \amp  0 \amp  1 \amp  2 \\
          1 \amp  -3 \amp  11 \amp  3 \amp  7 \\
          4 \amp  1 \amp  5 \amp  2 \amp  5
        \end{array}\right]</m>. Let us find the null space of <m>A</m>. That is,  find a basis of <m>{\cal N}(A)</m>.
        
        The null space of <m>A</m> is given by
       <md>
        <mrow>{\cal N}(A) =\amp  \{x\in \R^5:Ax=0\}</mrow>
        <mrow> =\amp  \left\{\begin{bmatrix} x_1\\x_2\\\vdots\\x_5\end{bmatrix}: 
        \left[\begin{array}{rrrrr}
          1 \amp  2 \amp  -4 \amp  -1 \amp  -2 \\
          -1 \amp  1 \amp  -5 \amp  0 \amp  -2 \\
          2 \amp  0 \amp  4 \amp  2 \amp  4 \\
          3 \amp  2 \amp  0 \amp  1 \amp  2 \\
          1 \amp  -3 \amp  11 \amp  3 \amp  7 \\
          4 \amp  1 \amp  5 \amp  2 \amp  5
        \end{array}\right]\begin{bmatrix} x_1\\x_2\\\vdots\\x_5\end{bmatrix}=\begin{bmatrix} 0\\0\\\vdots\\0\end{bmatrix}
        \right\}</mrow>
        <mrow>=\amp \left\{\begin{bmatrix} x_1\\x_2\\\vdots\\x_5\end{bmatrix}: 
        \left[\begin{array}{rrrrr}
          1 \amp  0 \amp  2 \amp  0 \amp  1 \\
          0 \amp  1 \amp  -3 \amp  0 \amp  -1 \\
          0 \amp  0 \amp  0 \amp  1 \amp  1 \\
          0 \amp  0 \amp  0 \amp  0 \amp  0 \\
          0 \amp  0 \amp  0 \amp  0 \amp  0 \\
          0 \amp  0 \amp  0 \amp  0 \amp  0
        \end{array}\right]
        \begin{bmatrix} x_1\\x_2\\\vdots\\x_5\end{bmatrix}=\begin{bmatrix} 0\\0\\\vdots\\0\end{bmatrix}
        \right\}\quad \text{using RREF}</mrow>
        <mrow> =\amp 
        \left\{\begin{bmatrix} x_1\\x_2\\\vdots\\x_5\end{bmatrix}: 
        x_1+2x_3+x_5=0, x_2-3x_3-x_5=0,x_4+x_5=0
        \right\}</mrow>
        <mrow> =\amp 
        \left\{\begin{bmatrix} \alpha\\\beta\\\alpha+\beta\\2\alpha+\beta\\-2\alpha-\beta\end{bmatrix}:\alpha,\beta\in\R \right\}</mrow>
        <mrow>  =\amp  
        \left\{
        \alpha \begin{bmatrix} 
          1 \\0\\1\\3\\-3\end{bmatrix}+\beta\begin{bmatrix} 
          0 \\1\\1\\2\\-2\end{bmatrix}:\alpha,\beta\in\R 
        \right\}
        </mrow>
      </md>
        Thus <m>\dim{{\cal N}(A)}=2</m> and <m>\delta =\{(1,0,1,3,-3),(0,1,1,2,-2)\}</m> is a basis of <m>{\cal N}(A)</m>. 
        
        The <m>\dim{{\cal N}(A)}</m> is called the nullity of <m>A</m>. 
        Notice that for this matrix <me>{\rm nullity}(A)+{\rm rank}(A)=\text{ number of columns of }A.</me>
        This is true for any matrix <m>A</m>.
        
        
        
      </example>
    </p>

    <p>
      <example>
        Consider the matrix <m>A=\left[\begin{array}{rrrrrr}
          1 \amp  -1 \amp  2 \amp  3 \amp  1 \amp  4 \\
          2 \amp  1 \amp  0 \amp  2 \amp  -3 \amp  1 \\
          -4 \amp  -5 \amp  4 \amp  0 \amp  11 \amp  5 \\
          -1 \amp  0 \amp  2 \amp  1 \amp  3 \amp  2 \\
          -2 \amp  -2 \amp  4 \amp  2 \amp  7 \amp  5
        \end{array}\right]</m>. Let us find the image space, <m>{\cal R}(A)</m> of <m>A</m>. 


        Let <m>b = \begin{bmatrix} b_1\\b_2\\b_3\\b_4\\b_5\end{bmatrix}\in {\cal R}(A)</m> lies in then there exists <m>x\in\R^6</m> such that <m>Ax=b</m>, In particular <m>Ax=b</m> has a solution. Thus to find a solution we apply the RREF to the augmented matrix <m>[A|b]</m>. It is easy to see that 
<me>RREF(A)=
\left[\begin{array}{rrrrrrr}
	1 \amp  0 \amp  0 \amp  1 \amp  -\frac{5}{4} \amp  \frac{3}{4} \amp  \frac{1}{4} b_{1} + \frac{1}{4} b_{2} - \frac{1}{4} b_{4} \\
	0 \amp  1 \amp  0 \amp  0 \amp  -\frac{1}{2} \amp  -\frac{1}{2} \amp  -\frac{1}{2} b_{1} + \frac{1}{2} b_{2} + \frac{1}{2} b_{4} \\
	0 \amp  0 \amp  1 \amp  1 \amp  \frac{7}{8} \amp  \frac{11}{8} \amp  \frac{1}{8} b_{1} + \frac{1}{8} b_{2} + \frac{3}{8} b_{4} \\
	0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  -2 b_{1} + 3 b_{2} + b_{3} \\
	0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  -b_{1} + b_{2} - b_{4} + b_{5}
\end{array}\right]
</me>
This means that <m>Ax=b</m> has a solution iff 
<me>-2 b_{1} + 3 b_{2} + b_{3}=0 \text{ and }-b_{1} + b_{2} - b_{4} + b_{5}=0</me>. Solving these equations, it is easy to see that 

<md>
  <mrow>
{\cal R}(A)=\amp \left\{\begin{bmatrix}
b_1\\b_2\\b_3\\b_4\\b_5
\end{bmatrix}: -2 b_{1} + 3 b_{2} + b_{3}=0, -b_{1} + b_{2} - b_{4} + b_{5}=0\right\}</mrow>
<mrow> =\amp  \left\{\begin{bmatrix}
	b_1\\b_2\\2b_1-3b_2\\b_4\\b_1-b_2+b4
\end{bmatrix}:b_1,b_2,b_4\in \R\right\}</mrow>
<mrow> =\amp \left\{b_1\begin{bmatrix}1\\0\\2\\0\\1\end{bmatrix}+
b_2\begin{bmatrix}0\\1\\-3\\0\\-1\end{bmatrix}+
b_4\begin{bmatrix}0\\0\\0\\1\\1\end{bmatrix}:b_1,b_2,b_4\in \R\right\}
</mrow>
</md>
Thus <me>
  \left\{\begin{bmatrix}1\\0\\2\\0\\1\end{bmatrix},
      \begin{bmatrix}0\\1\\-3\\0\\-1\end{bmatrix},
      \begin{bmatrix}0\\0\\0\\1\\1\end{bmatrix}
       \right\}
       </me>
       is a basis of <m>{\cal R}(A)</m> which is same as the column space of <m>A</m>.
  Note that <m>{\cal R}(A)</m> is null space of the matrix  
  <m>\begin{bmatrix} -2 \amp  3 \amp  1 \amp  0 \amp  0\\-1\amp  1\amp  0 \amp -1 \amp  1 \end{bmatrix}</m>.
  
      </example>
    </p>

  <p>
    <theorem xml:id="sec2-3-thm-rank-nullity">
      <statement>
        <p>
        	Let <m>A </m> be <m>m\times n</m> real matrix. Then 
	<me>{\rm rank}(A)+{\rm nullity}(A)=n</me>.  
        </p>
      </statement>
    </theorem>
    
  </p>


  <definition xml:id="def-sec2-1-coordinates">
      
    <statement>
      <p>
        Let <m>\beta =\{v_1,v_2,\ldots, v_n\}</m>be a basis of 
        <m>\R^n</m>. Let <m>x\in \R^n</m>. 
        Then we know that there exists unique scalars <m>x_1,\ldots, x_n</m> 
        such that <m>x=x_1v_1+x_2v_2+\cdots+x_nv_n</m>. Then <m>x_1,\ldots, x_n</m> 
        are called the <alert>coordinates</alert> of <m>x</m> with respect to the basis 
        <m>\beta</m>.

      </p>
    </statement>
</definition>
<p>
  Notice that the order in which basis vectors appear is important. 
  Suppose <m>\beta'=\{v_2,v_2,v_3\ldots, v_n\}</m>. 
  Then <m>\beta'</m> is also a basis of <m>\R^n</m>. However the coordinates of 
  <m>x</m> with respect to the basis <m>\beta'</m> is 
  <m>x_2,x_1,x_3,\ldots,x_n</m>. This is the reason basis of 
  <m>\R^n</m> is called an <alert>ordered basis</alert>. By a basis we will always mean 
  an ordered basis.
</p>

<p>
  <alert>How to find the coordinates of a vector w.r.t. a given basis?</alert>
</p>
<p>
Suppose <m>\beta=\{v_1,v_2,\ldots, v_n\}</m> be a basis of <m>\R^n</m> and <m>v\in \R^n</m>. 
How to find the coordinates of <m>v</m> with respect to <m>\beta</m>? 
Let <m>v =x_1v_1+x_2v_2+\cdots+x_nv_n</m>. We need to find <m>x_1,\cdots, x_n</m>. Note that 
<me>
v = x_1v_1+x_2v_2+\cdots+x_nv_n=
\begin{bmatrix} v_1\amp  v_2\cdots\amp v_n\end{bmatrix}
\begin{bmatrix}	x_1\\x_2\\\vdots\\x_n\end{bmatrix}=Ax.
</me>
Thus to find <m>x</m>, we need to solve <m>Ax=v</m>, where <m>A</m> is the matrix whose 
columns are <m>v_1,\ldots, v_n</m>. This can be done using the RREF. Let us illustrate this with few examples.

</p>

<p>
<example>
<p> If <m>x=(x_1,\ldots,x_n)\in \R^n</m>. 
Then <m>x=x_1e_1+x_2e_2+\cdots+x_ne_n</m>. In particular <m>x_1,x_2,\ldots, x_n</m> is the coordinate of 
<m>x</m> with respect to the standard basis <m>\{e_1,e_2,\ldots,e_n\}</m>.
</p>
</example>
</p>

<p>
<example>
<p> Consider a basis <m>\beta=\{(1,-1),(2,1)\}</m>. Find the coordinates of <m>v=(2,3)</m> with respect to <m>\beta</m>.  In order to find the coordinates of <m>v</m> with respect to <m>\beta</m>, we solve the system <m>Ax=b</m> where <m>A=\begin{bmatrix} 1 \amp  2\\-1\amp  1\end{bmatrix}</m> and <m>b = \begin{bmatrix} 2\\3\end{bmatrix}</m>. Using RREF 
  <me>
  [A~|~b]\xrightarrow{RREF} \left[\begin{array}{rr|r}
    1 \amp  0 \amp  -\frac{4}{3} \\
    0 \amp  1 \amp  \frac{5}{3}
  \end{array}\right]
  </me>
  Hence the coordinates of <m>v</m> w.r.t. <m>\beta</m> is <m>(-4/3,5/3)</m>.
</p>
</example>
</p>

<p>
<example>
<p>
  Find the coordinates of the vector <m>(1,2,3)</m> with respect to a basis\\ <m>\beta=\{(1,-1,1),(1,1,-1),(-1,1,1)\}</m> of <m>\R^3</m>. Using the RREF we have 
<me>
\left[\begin{array}{rrr|r}
1 \amp  1 \amp  -1 \amp  1 \\
-1 \amp  1 \amp  1 \amp  2 \\
1 \amp  -1 \amp  1 \amp  3
\end{array}\right] \xrightarrow{RREF} 
\left[\begin{array}{rrr|r}
1 \amp  0 \amp  0 \amp  2 \\
0 \amp  1 \amp  0 \amp  \frac{3}{2} \\
0 \amp  0 \amp  1 \amp  \frac{5}{2}
\end{array}\right]
</me>
Hence the coordinates of <m>(1,2,3)</m> with respect the given basis is <m>(2,3/2,5/2)</m>.

</p>
</example>
</p>

<p>
<example>
<p>
  Find the coordinates of the vector <m>(1,2,3,4)</m> with respect to a basis <m>\beta=\{(1,-1,1,1),(1,1,-1,1),(1,1,-1,1),(-1,1,1,1)\}</m> of <m>\R^4</m>. Using the RREF we have 
<me>
\left[\begin{array}{rrrr|r}
1 \amp  1 \amp  1 \amp  -1 \amp  1\\
-1 \amp  1 \amp  1 \amp  1  \amp  2\\
1 \amp  -1 \amp  1 \amp  1 \amp  3\\
1 \amp  1 \amp  -1 \amp  1 \amp  4
\end{array}\right] \xrightarrow{RREF} 
\left[\begin{array}{rrrr|r}
1 \amp  0 \amp  0 \amp  0 \amp  \frac{3}{2} \\
0 \amp  1 \amp  0 \amp  0 \amp  1 \\
0 \amp  0 \amp  1 \amp  0 \amp  \frac{1}{2} \\
0 \amp  0 \amp  0 \amp  1 \amp  2
\end{array}
\right]
</me>
Hence the coordinates of <m>(1,2,3)</m> with respect the given basis is <m>(3/2,1,1/2,2)</m>.
</p>
</example>
</p>
<subsection xml:id="sec2-3-change-of-basis">
<title>Change of bases.</title>
<p>
Let <m>\beta=\{u_1,u_2\ldots,u_n\}</m> and <m>\gamma=\{v_1,v_2\ldots,v_n\}</m> be two bases of <m>\R^n</m>. Fix a vector <m>x\in \R^n</m>.  Let <m>x_\beta=\begin{bmatrix}c_1\\\vdots \\c_n\end{bmatrix}</m>   and 
<m>x_\gamma=\begin{bmatrix}d_1\\\vdots \\d_n\end{bmatrix}</m>  be the coordinates of <m>x</m> with respect to 
<m>\beta</m> and <m>\gamma</m> respectively. Then we have 
<me>
x = \begin{bmatrix}u_1\amp \cdots \amp  u_n\end{bmatrix}\begin{bmatrix}c_1\\\vdots \\c_n\end{bmatrix}=Ax_\beta.
</me>

Similarly 
<me>
x = \begin{bmatrix}v_1\amp \cdots \amp  v_n\end{bmatrix}\begin{bmatrix}d_1\\\vdots \\d_n\end{bmatrix}=Bx_\gamma.
</me>
Thus we have 
<me>
Ax_\beta=Bx_\gamma\implies x_\beta = A^{-1}B x_\gamma \text{ and } x_\gamma = B^{-1}Ax_\beta.
</me>
The matrices <m>A^{-1}B</m> and <m>B^{-1}A</m> are called <alert>transition matrices</alert>. We denotes <m>A^{-1}B</m> by <m>[I]_\gamma^\beta</m> and <m>B^{-1}A</m> by <m>[I]_\beta^\gamma</m>. Note that <m>[I]_\beta^\gamma=\left([I]_\gamma^\beta\right)^{-1}.</m>

<p>
Furthermore, the transition matrix <m>I_\gamma^\beta</m> can be obtained by applying RREF to the 
<m>[A|B]</m> and extracting the last <m>n</m> columns. Let us illustrate this with an example.
</p>
</p>

<p>
<example>
<p>
  Consider 
<m>\beta = \left\{\left(2,-1,3\right), \left(3,1,2\right), \left(1,1,1\right)\right\}</m>, 
and  
<m>\gamma = \left\{\left(1,-1,1\right), \left(1,1,-1\right), \left(-1,1,1\right)\right\}
</m> be two bases of <m>\R^3</m>.  Consider a vector <m>x=(1,2,3)</m>.  We have 
<me>
A = \left(\begin{array}{rrr}
2 \amp  3 \amp  1 \\
-1 \amp  1 \amp  1 \\
3 \amp  2 \amp  1
\end{array}\right), B = \left(\begin{array}{rrr}
1 \amp  1 \amp  -1 \\
-1 \amp  1 \amp  1 \\
1 \amp  -1 \amp  1
\end{array}\right)
</me>
First we find <m>x_\beta</m> and <m>x_\gamma</m>. 
<me>
\left(\begin{array}{rrr|r}
2 \amp  3 \amp  1 \amp  1 \\
-1 \amp  1 \amp  1 \amp  2 \\
3 \amp  2 \amp  1 \amp  3
\end{array}\right)
\xrightarrow{RREF}
\left(\begin{array}{rrr|r}
1 \amp  0 \amp  0 \amp  \frac{3}{5} \\
0 \amp  1 \amp  0 \amp  -\frac{7}{5} \\
0 \amp  0 \amp  1 \amp  4
\end{array}\right)
</me>
<me>\implies x_\beta =\begin{pmatrix} 3/5\\7/5\\4\end{pmatrix}.
</me>
Similarly
<me>
\left(\begin{array}{rrr|r}
1 \amp  1 \amp  -1 \amp  1 \\
-1 \amp  1 \amp  1 \amp  2 \\
1 \amp  -1 \amp  1 \amp  3
\end{array}\right)\xrightarrow{RREF}
\left(\begin{array}{rrr|r}
1 \amp  0 \amp  0 \amp  2 \\
0 \amp  1 \amp  0 \amp  \frac{3}{2} \\
0 \amp  0 \amp  1 \amp  \frac{5}{2}
\end{array}\right)
</me>
<me>\implies x_\gamma =\begin{pmatrix} 2\\3/2\\5/2\end{pmatrix}.
</me>
Now to find the transition matrix <m>[I]_\gamma^\beta</m>, we have
<me>
[A~|~B]\xrightarrow{RREF} \left(\begin{array}{rrr|rrr}
1 \amp  0 \amp  0 \amp  \frac{2}{5} \amp  -\frac{4}{5} \amp  \frac{2}{5} \\
0 \amp  1 \amp  0 \amp  \frac{2}{5} \amp  \frac{6}{5} \amp  -\frac{8}{5} \\
0 \amp  0 \amp  1 \amp  -1 \amp  -1 \amp  3
\end{array}\right) 
</me>
<me>\implies [I]_\gamma^\beta =
\left(\begin{array}{rrr}
\frac{2}{5} \amp  -\frac{4}{5} \amp  \frac{2}{5} \\
\frac{2}{5} \amp  \frac{6}{5} \amp  -\frac{8}{5} \\
-1 \amp  -1 \amp  3
\end{array}\right) 
</me>
It is easy to verify that <m>x_\beta = [I]_\gamma^\beta x_\gamma</m>. 

Similarly to find the transition matrix <m>[I]_\beta\gamma</m>, we have
<me>
[B~|~A]\xrightarrow{RREF} \left(\begin{array}{rrr|rrr}
1 \amp  0 \amp  0 \amp  \frac{5}{2} \amp  \frac{5}{2} \amp  1 \\
0 \amp  1 \amp  0 \amp  \frac{1}{2} \amp  2 \amp  1 \\
0 \amp  0 \amp  1 \amp  1 \amp  \frac{3}{2} \amp  1
\end{array}\right)</me>
<me>
\implies [I]_\beta^\gamma =\left(\begin{array}{rrr}
\frac{5}{2} \amp  \frac{5}{2} \amp  1 \\
\frac{1}{2} \amp  2 \amp  1 \\
1 \amp  \frac{3}{2} \amp  1
\end{array}\right)
</me>
It is easy to verify that <m>x_\gamma=[I]_\beta^\gamma x_\beta</m>.
</p>
</example>
</p>


</subsection>
<p>
<problem>
What are all subspaces of <m>\R^2</m> and <m>\R^3</m>?
</problem>
</p>

<p>
<problem>
If <m>W</m> is a subspace of <m>\R^n</m>, then it is null space of some matrix.
</problem>
</p>

We end this chapter by look at a bigger example. Here we also illustrate RREF gives several informations 
on a matrix.

<p>

<example>
<p>
Consider a set of 7 vectors <m>v_1,\ldots, v_7\in \R^7</m>. 

<me> v_1=\left(\begin{array}{r}
1 \\
-1 \\
2 \\
0 \\
3 \\
2 \\
1
\end{array}\right), 
v_2=\left(\begin{array}{r}
2 \\
1 \\
0 \\
2 \\
-3 \\
0 \\
1
\end{array}\right), 
v_3=\left(\begin{array}{r}
-1 \\
-5 \\
6 \\
-4 \\
15 \\
6 \\
1
\end{array}\right), 
v_4=\left(\begin{array}{r}
0 \\
2 \\
3 \\
1 \\
-1 \\
3 \\
-1
\end{array}\right),
v_5=\left(\begin{array}{r}
4 \\
3 \\
1 \\
2 \\
0 \\
1 \\
3
\end{array}\right),</me>
<me>
v_6=\left(\begin{array}{r}
-13 \\
-30 \\
4 \\
-22 \\
52 \\
4 \\
0
\end{array}\right),
v_7=\left(\begin{array}{r}
-2 \\
-1 \\
0 \\
1 \\
2 \\
3 \\
4
\end{array}\right)
</me>

Define the matrix <m>A</m> whose columns are <m>v_1,\ldots, v_7</m> and apply RREF to <m>A</m>.
<me>
A=\left(\begin{array}{rrrrrrr}
1 \amp  2 \amp  -1 \amp  0 \amp  4 \amp  -13 \amp  -2 \\
-1 \amp  1 \amp  -5 \amp  2 \amp  3 \amp  -30 \amp  -1 \\
2 \amp  0 \amp  6 \amp  3 \amp  1 \amp  4 \amp  0 \\
0 \amp  2 \amp  -4 \amp  1 \amp  2 \amp  -22 \amp  1 \\
3 \amp  -3 \amp  15 \amp  -1 \amp  0 \amp  52 \amp  2 \\
2 \amp  0 \amp  6 \amp  3 \amp  1 \amp  4 \amp  3 \\
1 \amp  1 \amp  1 \amp  -1 \amp  3 \amp  0 \amp  4
\end{array}\right)
</me>
<me>
RREF(A)=\left(\begin{array}{rrrrrrr}
1 \amp  0 \amp  3 \amp  0 \amp  0 \amp  9 \amp  0 \\
0 \amp  1 \amp  -2 \amp  0 \amp  0 \amp  -7 \amp  0 \\
0 \amp  0 \amp  0 \amp  1 \amp  0 \amp  -4 \amp  0 \\
0 \amp  0 \amp  0 \amp  0 \amp  1 \amp  -2 \amp  0 \\
0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  1 \\
0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  0 \\
0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  0
\end{array}\right)
</me>

From the RREF of <m>A</m>, we have the following observations:

<p>
(i) The reduced row-echelon form of <m>A</m> has 5 non zero rows. This means the rank of <m>A</m> is 5. 
In particular, <m>A</m> is singular.</p> 

<p>(ii) The pivots columns are 1, 2, 4, 5, 7. In particular, <m>\{v_1,v_2,v_4,v_5,v_7\}</m> 
are linearly independent and forms a basis of the subspace spanned by <m>\{v_1,v_2,v_4,v_5,v_7\}</m>.
</p>

<p> 
(iii) The 3rd columns gives <m>v_3</m> as linear combinations of <m>v_1</m> and <m>v_2</m>. 
In particular, <m>v_3=3v_1-2v_2</m>. Similarly <m>v_6=9v_1-7v_2-4v_4-2v_5</m>.
</p>

<p>
(iv) Since rank of <m>A</m> is 5, the nullity of <m>A</m> is 2.
</p>

<p>
(v) First five rows of <m>RREF(A)</m> constitute a basis of the row space of <m>A</m>.
</p>




</p>  
</example>
</p>



  <!--
<p>
  <figure xml:id="fig-sage-cubic">
    <caption>A cubic plotted by SageMath on
    <m>[-3,2]</m></caption>
    <image xml:id="sageplot-cubic" width="50%">
      <description>A cubic function on the interval
      [-3,2]</description>
  
  <sageplot>
  f(x) = (x-1)*(x+1)*(x-2)
  plot(f, (x, -3, 2), color='blue', thickness=3)
  </sageplot>
    </image>
  
  </figure>
</p>

<p>
  <image source="small-graph" width="20%">
    <description>A graph on five vertices.</description>
</image>
</p>

<p>
  <figure xml:id="fig-graph">
    <caption>A small graph (from <pubtitle>Applied
    Combinatorics</pubtitle> by Keller and
    Trotter)</caption>
    <image source="small-graph" width="20%"/>
  </figure>

</p>
-->
</section>
