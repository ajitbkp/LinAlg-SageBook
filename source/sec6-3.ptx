<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec6-3" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Orthogonal Diagonalizations</title>

 <introduction>
  <p>
    Recall the concept of diagonalization of a square matrix. We have seen that an 
    <m>n\times n</m> matrix <m>A</m> is diagonalizable 
    if there is an eigenbasis of <m>\R^n</m>. In this section, we shall explore 
    if we can find an eigenbasis which is also an orthonormal. First of all we shall define 
    what is meaning of an orthogonal matrix. 
  </p>
 </introduction>
  
  
    <theorem xml:id="thm-orthogonal-matrix">
      <statement>
        <p>
          Let <m>P</m> be an <m>n\times n</m> matrix.
          Then the following are equivalent:
       <ol>
        <li>
           <p>
       <m>P</m> is non-singular and <m>P^{-1}=P^T</m>.
        </p>
      </li>
       <li>
         <p>
       The rows of <m>P</m> are orthonormal vectors in <m>\R^n</m>. 
        </p>
      </li>
      <li>
        <p>
       The columns of <m>P</m> are orthonormal vectors in <m>\R^n</m>.
        </p>  
        </li>
       </ol>
      </p>
      </statement>

      <proof>
         <p>
            Assume that <m>P^{-1}=P^T</m>. This implies <m>PP^T=I</m>. Let the columns 
            of <m>P</m> are <m>p_1, p_2,\ldots, p_n</m>. Then <m>\{p_1,\ldots, p_n\}</m> is 
            linearly independent. It is easy to see that the <m>ij</m>-th entry of <m>PP^T</m> is 
            <m>p_i\cdot p_j</m>. Hence we have <m>p_i\cdot p_j=\delta_{ij}=1</m> if <m>i=j</m> 
            and 0 otherwise. This proves rows of <m>P</m> and orthogonal and hence columns 
            of <m>P</m> are orthogonal. The converse is easy.
         </p>
      </proof>

    </theorem>

  

    <definition xml:id="def-orthogonal-matrix">
      <statement>
        <p>
          A square matrix <m>P</m> is called an orthogonal matrix if it satisfies any one
          (and hence all) the conditions of Theorem
          <xref ref="thm-orthogonal-matrix"></xref>.
        </p>
      </statement>
    </definition>
  


     <example>
      <statement>
        <p>
       <ol>
        <li>
          <p>
            The matrix <m>\begin{pmatrix}\cos \theta \amp -\sin\theta\\\sin\theta \amp \cos\theta \end{pmatrix}</m> 
            is an orthogonal matrix.
          </p>
        </li>
        <li>
          <p>
            <m>\left(\begin{array}{rrr} -\frac{1}{3} \, \sqrt{3} \amp \sqrt{\frac{2}{3}} \amp 0 \\ 
              \frac{1}{3} \, \sqrt{3} \amp \frac{1}{2} \, \sqrt{\frac{2}{3}} \amp -\sqrt{\frac{1}{2}} \\ 
              \frac{1}{3} \, \sqrt{3} \amp \frac{1}{2} \, \sqrt{\frac{2}{3}} \amp \sqrt{\frac{1}{2}} 
              \end{array} \right)</m> 
            is an orthogonal matrix.
        
          </p>
        </li>
       </ol>
         </p>
      </statement>
    </example>
    
  

  
    <definition xml:id="def-orthogonally-diagonalizable">
      <statement>
        <p>
          An <m>n\times n</m> matrix is called
          <em>orthogonally diagonalizable </em>
          if there exists an orthogonal matrix <m>P</m> such that
          <m>P^{-1}AP=P^TAP</m> is a diagonal matrix.
        </p>
      </statement>
    </definition>


  <p>
    It is easy to easy to see that if <m>P</m> and <m>Q</m> are 
    orthgogonal matrices then <m>PQ</m> is also orthogonal. (why?)
  </p>

      <definition xml:id="def-orthogonally-similar-matrics">
      <statement>
        <p>
          Two  <m>n\times n</m> matrices <m>A</m> and <m>B</m> are called
          <em>orthogonally similar </em>
          if there exists an orthogonal matrix <m>P</m> such that
          <m>B =P^{-1}AP=P^TAP</m> is a diagonal matrix.
        </p>
      </statement>
    </definition>

<p>
  Thus an orthogonally diagonally matrix is ortghogonally similar to a diagonal matrix.
</p>

<p>
  Suppose a matrix <m>A</m> is orthogonally diagonalizable. That is <m>P^TAP=D</m>, a digonal matrix. 
  This means <m>A=PDP^T</m>. Hence 
  <me>
    A^T=(PDP^T)^T=PD^TP^T=PDP^T=A.
  </me>
  Thus if <m>A</m> is orthogonally diagonalizable then <m>A</m> must be symmetric. 
</p>
 
<lemma xml:id="lemma-orthogonality-eigenvectors1">
      <statement>
        <p>
          Let <m>A</m> be a symmetric matrix and <m>\lambda_1</m> and
          <m>\lambda_2</m> are distinct eigenvalues of <m>A</m>.
          If <m>v_1</m> and <m>v_2</m> are eigenvectors corresponding to
          <m>\lambda_1</m> and <m>\lambda_2</m> respectively.
          Then <m>v_1</m> and <m>v_2</m> are orthogonal.
        </p>
      </statement>

      <proof>
        <p>
          We have 
          <me>
            (\lambda_1 v_1)\cdot v_2 = (Av_1) \cdot (v_2)=
            {(Av_1)}^T(v_2)=v_1^T A^Tv_2=v_1^T(\lambda_2 v_2).
          </me>
          This implies <m>(\lambda_1-\lambda_2)(v_1\cdot v_2)=0</m>. Since <m>\lambda_1\neq \lambda_2</m>, 
          we have <m>v_1\cdot v_2=0</m>.
        </p>
      </proof>
    </lemma>
  
<p>
  The following therem shows that every real symmetric matrix is orthogonally 
  diagonalizable. 
</p>

<theorem xml:id="thm-6-4-6">
  <statement>
    <p>
          Let <m>A</m> be an <m>n\times n</m> real matrix.
          Then the following are equivalent.
        </p>
        <ol>
          <li>
            <p>
             <m>A</m> has an orthonormal set of eigenvectors.
            </p>
          </li>
        <li>
          <p>
            <m>A</m> is orthogonally diagonalizable.
          </p>
        </li>
      <li>
        <p>
           <m>A</m> is symmetric.
        </p>
      </li>  
      </ol>
    </statement>

  <proof>
  <p>
  Let <m>v_1,\ldots, v_n</m> be orthogonormal eigenvectors of <m>A</m> such that 
  <m>Av_i=\lambda_i v_i</m>. Then 
  <m>P=\begin{bmatrix} v_1\amp v_2\cdots v_n\end{bmatrix}</m> is orthogonal. Hence 
  <me>
    P^TAP={\rm diag}(\lambda_1,\ldots,\lambda_n)=D. 
  </me>
  Hence <m>A</m> is orthogonally diagonalizable. 
  </p>

  <p>
    If <m>A</m> is orthogonally diagonalizable with <m>P^TAP=D</m> then 
    <me>
      A^T={(PDP^T)}^T=PDP^T=A.
    </me>
    Hence <m>A</m> is symmetric. 
  </p>
  
</proof>

</theorem>

    <example>
      <statement>
        <p>
          Consider a matrix <m>A=\left(\begin{array}{rrr} 5 \amp  -2 \amp  -4 \\ -2 \amp  8 \amp  -2 \\ -4 \amp  -2 \amp  5 \end{array} \right)</m>.
          Clearly <m>A</m> is symmetric and hence it is orthogonally diagonalizable.
          The characteristic polynomial of <m>A</m> is
          <me>
            det(xI-A)=x^3 - 18*x^2 + 81*x=x(x-9)^2
          </me>.
        </p>
        <p>
          Hence <m>0, 9, 9</m> are eigenvalues of <m>A</m>.
          Its is easy to find that <m>v_1=(1, 1/2, 1)</m> is an eigenvector corresponding to the eigenvalue 0.
          <m>v_2=(1, 0, -1), v_2=(0, 1, -1/2)</m> are eigenvectors corresponding to eigenvalue 9.
          Hence <m>P:=\left(\begin{array}{rrr} 1 \amp  1 \amp  0 \\ \frac{1}{2} \amp  0 \amp  1 \\ 1 \amp  -1 \amp  -\frac{1}{2} \end{array} \right)</m>.
          Then
          <me>
            P^{-1}AP=\left(\begin{array}{rrr} 0 \amp  0 \amp  0 \\ 0 \amp  9 \amp  0 \\ 0 \amp  0 \amp  9 \end{array} \right)
          </me>
        </p>
      </statement>
    </example>
  


    <problem>
      <statement>
        <p>
          For the following matrices find an orthogonal matrix <m>P</m> such that
          <m>P^{-1}AP</m> is a diagonal matrix.
          <me>
            \begin{pmatrix}2 \amp  -1 \\-1 \amp  1 \end{pmatrix} , \begin{pmatrix}1 \amp  0 \amp  -1\\0 \amp  1 \amp  2\\-1 \amp  2 \amp  5 \end{pmatrix}
          </me>
        </p>
      </statement>
    </problem>

  <theorem>
      <statement>
        <p>
          The following are equivalent for an <m>n\times n</m> matrix <m>A</m>.
        </p>
        <p>
          <ol>
            <li>
              <p>
                <m>A</m> is orthogonal.  
              </p>
            </li>
            <li>
              <p>
                <m>\norm{Ax}=\norm{A}</m> for all <m>x\in \R^n</m>. 
              </p>
            </li>
            <li>
              <p>
                <m>\norm{Ax-Ay}=\norm{x-y}</m> for all <m>x,y\in \R^n</m>.
              </p>
            </li>
            <li>
              <p>
                <m>Ax\cdot Ay = (Ay)^TAx=x\cdot y</m>.
              </p>
            </li>
          </ol> 
        </p>
      </statement>
    </theorem>
      
  <subsection xml:id="subsec-6-3-quadratic-form">
    <title>Quadratic Forms and Conic Sections</title>
      <p>
        In this subsection, we give an application of orthogonal diagonalizability  to conic sections.
      </p>
    
      <p>
            A general second-degree equation in two variables is given by
            <me>
                Q(x,y) = ax^2 + 2bxy + cy^2 + dx + ey + f = 0,
            </me>
            where <m>a,b,c,d,e,f \in \mathbb{R}</m>.
        </p>

          <p>
            This equation can be written compactly in matrix notation as
            <me>
                Q(x,y) =
                \begin{bmatrix}x \amp y\end{bmatrix} 
                \begin{bmatrix} a \amp b \\ b \amp c \end{bmatrix}
                \begin{bmatrix}x \\ y\end{bmatrix}+ \begin{bmatrix} d \amp e \end{bmatrix} 
                \begin{bmatrix} x \\ y \end{bmatrix} + f = 0.
            </me>
        </p>
        <p>
            Here,
            <me>
               A = \begin{bmatrix} a \amp b \\ b  \amp c \end{bmatrix}
            </me>
            is the symmetric matrix associated with the quadratic part <m>ax^2+2bxy+cy^2</m>.
        </p>

         <p>
            Since <m>A</m> is symmetric, it is orthogonally diagonalizable.  
            That is, there exists an orthogonal matrix <m>P</m> such that
            <me>
                P^TAP = D = \begin{pmatrix} \lambda_1 \amp 0\\ 0 \amp \lambda_2\end{pmatrix},
            </me>
            where <m>\lambda_1,\lambda_2</m> are eigenvalues of <m>A</m> and <m>P</m> is 
            the column matrix of orthogonal eigenbasis.
        </p>

<p> 
        With the change of variables
        <me>
        \begin{bmatrix} x \\ y \end{bmatrix} = P \begin{bmatrix} u \\ v \end{bmatrix},
        </me> the quadratic form simplifies to
        <me>Q(u,v) = \lambda_1 u^2 + \lambda_2 v^2 + \alpha u+\beta v + f = 0.</me>  
        Note that here
   <me>
    \begin{bmatrix}\alpha\\\beta\end{bmatrix} =\begin{bmatrix}d\amp e\end{bmatrix}P. 
   </me>

Thus, the cross term <m>2bxy</m> is eliminated by using the 
orthogonal linear trasformation <m>\begin{bmatrix} u \\ v \end{bmatrix}=P\begin{bmatrix} x \\ y \end{bmatrix} </m> 
and the conic aligns with its principal axes, that 
is along the eigenvectors directions. 
</p>

<p>
   Now we have various cases. 
   If we assume that <m>\lambda_1</m> and <m>\lambda_2</m> are positive,  then 
   we can complete square and we get
   <me>
    Q(u,v) = \lambda_1\left(u+\frac{\alpha}{2\lambda_1}\right)^2+
    \lambda_2\left(v+\frac{\beta}{2\lambda_2}\right)^2-g,
   </me>
    for some real number <m>g</m>.  What is <m>g</m>? It is <m>\left(\frac{\alpha^2}{4\lambda_1}
        + \frac{\beta^2}{4\lambda_2} - f\right)</m>.
    </p>

    <p> 
The origin of this quadratic in <m>uv</m>-coordinates is 
<me> \begin{bmatrix} u_0\\v_0\end{bmatrix}=
  \begin{bmatrix}-\frac{\alpha}{2\lambda_1}\\-\frac{\beta}{2\lambda_2}\end{bmatrix}.
</me>
Hence the orgin in terms of <m>xy</m>-coordinates is 
<me> \begin{bmatrix} x_0\\y_0\end{bmatrix}=
  P\begin{bmatrix}-\frac{\alpha}{2\lambda_1}\\-\frac{\beta}{2\lambda_2}\end{bmatrix}.
</me>
Thus we have converted the original quadratic <m>Q(x,y)</m> to 
<me>
Q(\tilde{x},\tilde{y})=\lambda_1\tilde{x}^2+\lambda_2\tilde{y}^2-g =
\frac{\tilde{x}^2}{\left(\frac{g}{\lambda_1}\right)^2}+\frac{\tilde{y}^2}{\left(\frac{g}{\lambda_1}\right)^2}-1.
</me>
This is an ellipse.

Here,  we have
<me>
  \begin{pmatrix}
  \tilde{x}\\ \tilde{y}
  \end{pmatrix} = \begin{pmatrix} u+\frac{\alpha}{2\lambda_1}\\v+\frac{\beta}{2\lambda_2}\end{pmatrix}
  =\begin{pmatrix} u\\v\end{pmatrix}+\begin{pmatrix} \frac{\alpha}{2\lambda_1}\\\frac{\beta}{2\lambda_2}\end{pmatrix}=
  P^{-1}\begin{pmatrix}x\\y
  \end{pmatrix}+\begin{pmatrix} \frac{\alpha}{2\lambda_1}\\\frac{\beta}{2\lambda_2}\end{pmatrix}.
</me> 

The transformation, <m>P^{-1}\begin{pmatrix}x\\y
  \end{pmatrix}+\begin{pmatrix} \frac{\alpha}{2\lambda_1}\\\frac{\beta}{2\lambda_2}\end{pmatrix} </m> is called an <em>affine linear transformation.</em> Here <m>P^{-1}</m> is a orthogonl linear map.

 Thus an <em>affine linear transformation</em> on <m>\R^n</m> is a map of the form <m>T(x)=Px+v</m> ,where <m>P</m> is an 
orthogonal transformation and <m>v</m> is a called a translation vector. Such maps are also called 
<em>isometries.</em>
</p>

<p>
  In case, <m>\lambda_1</m> and <m>\lambda_2</m> both are negative then, we can multiply the 
  whole equation by <m>-1</m> and we get the a similar expression except, the right hand changes 
  its sign.
</p>
  
<p>
  In case one of the <m>\lambda's</m>, say <m>\lambda_2&lt;0</m>, then the conic tranforms to 
  <me>
    Q(\tilde{x},\tilde{y})=\lambda_1\tilde{x}^2-\lambda_2\tilde{y}^2-g, 
  </me>
  which is a hyperbola.
</p>


<p>
  In case one of the <m>\lambda's</m>, say <m>\lambda_2=0</m>, then the conic tranforms to 
  <me>
    Q(\tilde{x},\tilde{y})=\lambda_1\tilde{x}^2+\beta \tilde{y} -g, 
  </me>
  which is parabola. Here <m>\tilde{y}=v</m> and <m>g=\alpha^2/(4\lambda_1)-f</m>.
</p>

<p><alert>Classification of Conics in two variables</alert></p>


        <p>Based on the above discussions, the classification of the above conic section 
          depends on the eigenvalues of <m>A</m>.</p>
<p>
        <ul>
            <li>
                <p><em>Ellipse:</em> If both eigenvalues <m>\lambda_1, \lambda_2</m> 
                  have the same sign, then the quadratic is an ellipe of the form 
                  <m>x^2/a^2+y^2/b^2=1</m>.
                </p>
            </li>
            <li>
                <p><em>Circle:</em> When <m>\lambda_1 = \lambda_2</m>, then the quadratic is circle.</p>
            </li>
            <li>
                <p><em>Hyperbola:</em> If eigenvalues have opposite signs, then the quadratic is a hyperbola of the form 
                <me>x^2/a^2 -y^2/b^2= 1.</me> </p>
            </li>
            <li>
                <p><em>Parabola:</em> If one eigenvalue is zero, then it is a parabola.</p>
            </li>
        </ul>
      </p>


      <example xml:id="eg-conic-ellipe1">
        <statement>
          <p>
         Condiser the quadratic <m>(Q(x,y)=7 \, x^{2} - 6 \, x y + 7 \, y^{2} - 2 \, x + 3 \, y - 24</m>. Let us convert this 
         quadrtic into a conic section in canonial form.    
          </p>
        </statement>
       <solution>
        <p>
          The associated symmetric matrix of this quadratic <m>A</m> is given by 
          <me>
            A = \begin{pmatrix} 7 \amp -3 \\-3 \amp 7\end{pmatrix}.
          </me>
          It is easy to check the the eigenvalues of <m>A</m> are <m>\lambda_1=10</m> and <m>\lambda_2=4</m> with 
          the corresponding eigenvectors <m>v_1 = \left(\frac{1}{2} \, \sqrt{2},\,-\frac{1}{2} \, \sqrt{2}\right)</m> and 
          <m>v_2=\left(\frac{1}{2} \, \sqrt{2},\,\frac{1}{2} \, \sqrt{2}\right)</m>. Hence we have 
          <me>
            D= \left(\begin{array}{rr}
10 \amp 0 \\
0 \amp 4
\end{array}\right), P = \left(\begin{array}{rr}
\frac{1}{\sqrt{2}}  \amp \frac{1}{\sqrt{2}} \\
-\frac{1}{\sqrt{2}} \amp \frac{1}{\sqrt{2}}
\end{array}\right).
          </me>      
  The new coordinates in terms of <m>uv</m> is 
  <me>
    \begin{bmatrix} x \\ y \end{bmatrix} = P \begin{bmatrix} u \\ v \end{bmatrix}=\left(\begin{array}{rr}
\frac{1}{\sqrt{2}} u + \frac{1}{\sqrt{2}}  v \\ -\frac{1}{\sqrt{2}}  u + \frac{1}{\sqrt{2}v} 
\end{array}\right).
  </me>
   Now substituting <m>x=\frac{1}{\sqrt{2}} u + \frac{1}{\sqrt{2}}  v</m> and <m>y=-\frac{1}{\sqrt{2}} u + \frac{1}{\sqrt{2}} v </m> in the given quadratic, we get
   <me>
    Q(u,v)=10 \, u^{2} + 4 \, v^{2} - 7 \, \sqrt{2} u + \sqrt{2} v - 56.
   </me>
   After completing the squares, we get
   <me>
    Q(u,v)=10 \left(u- \frac{7\sqrt{2}}{20}\right)^2+ 4 \left(v+ \frac{\sqrt{2}}{8}\right)^2 - 2343/40.
   </me>
   This can be written as an equation of ellipes. Note that here the translation vector is given by
   <me>
    \begin{pmatrix}x_0\\y_0\end{pmatrix}=P\begin{pmatrix} \frac{7\sqrt{2}}{20}\\\frac{-\sqrt{2}}{8}\end{pmatrix}=
    \begin{pmatrix}\frac{9}{40}\\ -\frac{19}{40}\end{pmatrix}.
   </me>
   
        </p>
        <p>
          Let us explore this in Sage. Here we plot the orginal quadratic curve along with 
          the transformed coordinates.  

          <sage>
            <input>
          var('x,y')
var('u,v')
var('s,t')
var('z')
X = vector([x,y])
Y = vector([u,v])
a,b,c,d,e,f = 7,-3,7,-6,8,-56
Q(x,y) = a*x^2+2*b*x*y+c*y^2+d*x+e*y+f
print('The curve is given by')
show(Q(x,y))
curve = implicit_plot(Q(x,y),(x,-4,4),(y,-4,4),gridlines=True,aspect_ratio=1)
xaxis=line([(-4,0),(4,0)],color='black')
yaxis=line([(0,-4),(0,4)],color='black')
show(curve+xaxis+yaxis)
## We define the associated matrix A
A= matrix([[a,b],[b,c]])
B= vector([d,e])
print('The quadratic in terms of matrices A and B')
show(expand(X.dot_product(A*X))+B.dot_product(X)+f)

## Orthogonal Diagonalization of the matrix A
print(f'The eigenvalues of A are {A.eigenvalues()}')
D,P = A.eigenmatrix_right();
lam1 = D[0,0]
lam2 = D[1,1]

## We normalize the eigenvectors and redefine P
v1 = P.columns()[0]/norm(P.columns()[0])
v2 = P.columns()[1]/norm(P.columns()[1])
P = column_matrix([v1,v2])
print('To check if PDP^{-1}=A')
print(P*D*P.inverse())

## The qudratic in terms of new coordinate system uv
R(u,v)=expand(Q.substitute(x=(P*Y)[0],y=(P*Y)[1])(u,v));
print(R(u,v))

## The translation vector
alpha = (B*P)[0]
beta = (B*P)[1]
x0=-alpha/(2*lam1)
y0=-beta/(2*lam2)
g = (alpha)^2/(4*lam1)+(beta)^2/(4*lam2)-f
show(g)
print('The quadatic in canonical form is')
S(s,t)=expand(R.subs(u=s-alpha/(2*lam1),v=t-beta/(2*lam2))(s,t))
show(S(s,t))
## Plotting the ellipes withe major-minor arix
origin = P*vector([x0,y0])
neworigin = point([(origin[0],origin[1])],color='green')
newxaxis = parametric_plot(origin+z*v1, (z,-5,5),color='green')
newyaxis = parametric_plot(origin+z*v2, (z,-5,5),color='green')
show(curve+neworigin+newxaxis+newyaxis+xaxis+yaxis,aspect_ratio=1)
            </input>
            <output>
              
            </output>
          </sage>
        </p>
       </solution>
      </example>
    <example>
      <p>
      Consider the quadratic equation  <m>3x^{2}+4xy + 2 y^{2} - 8 x + 6 y-3=0</m>. We wish the classify this as a conic section.
        </p>
       
       <p>   
        Let us first plot the graph of this curve in Sage.
      </p>
  <sage>
  <input>
    var('x,y')
    curve = implicit_plot(3*x^2 + 4*x*y + 2*y^2 - 8*x + 6*y - 3==0,(x,-5,20),(y,-20,10),gridlines=True,aspect_ratio=1)
    xaxis=line([(-5,0),(20,0)],color='black')
    yaxis=line([(0,-20),(0,10)],color='black')
    show(curve+xaxis+yaxis)

  </input>
  <output>
    
  </output>
</sage>

<p>
  The symmetric matrix associated with quadratic tem is given by 
            <me>A = \begin{pmatrix}3 \amp 2 \\ 2 \amp 2 \end{pmatrix}</me>.

           It is easy to check that  he eigenvalues are <m>\lambda_1=0.4384471871911698, \lambda_2=4.561552812808830</m>.  Since 
           both the eigenvalues are positive, this quadratic is an ellipse. This is what the graph shows. 
        </p>

 <p>
  Now we give all the steps in Sage to plot the curve along with the now coordinate system.   
 </p>       

 <sage>
  <input>
var('x,y')
var('u,v')
var('s,t')
var('z')
X = vector([x,y])
Y = vector([u,v])
a,b,c,d,e,f = 3,2,2,-8,6,-3
Q(x,y) = a*x^2+2*b*x*y+c*y^2+d*x+e*y+f
print('The curve is given by')
show(Q(x,y))
curve = implicit_plot(Q(x,y),(x,-5,20),(y,-20,10),gridlines=True,aspect_ratio=1)
xaxis=line([(-5,0),(20,0)],color='black')
yaxis=line([(0,-20),(0,10)],color='black')
show(curve+xaxis+yaxis)
## We define the associated matrix A
A= matrix([[a,b],[b,c]])
B= vector([d,e])
print('The quadratic in terms of matrices A and B')
show(expand(X.dot_product(A*X))+B.dot_product(X)+f)

## Orthogonal Diagonalization of the matrix A
print(f'The eigenvalues of A are {A.eigenvalues()}')
D,P = A.eigenmatrix_right();
lam1 = D[0,0]
lam2 = D[1,1]

## We normalize the eigenvectors and redefine P
v1 = P.columns()[0]/norm(P.columns()[0])
v2 = P.columns()[1]/norm(P.columns()[1])
P = column_matrix([v1,v2])
print('To check if PDP^{-1}=A')
print(P*D*P.inverse())

## The qudratic in terms of new coordinate system uv
R(u,v)=expand(Q.substitute(x=(P*Y)[0],y=(P*Y)[1])(u,v));
print(R(u,v))

## The translation vector
alpha = (B*P)[0]
beta = (B*P)[1]
x0=-alpha/(2*lam1)
y0=-beta/(2*lam2)
g = (alpha)^2/(4*lam1)+(beta)^2/(4*lam2)-f
show(g)
print('The quadatic in canonical form is')
S(s,t)=expand(R.subs(u=s-alpha/(2*lam1),v=t-beta/(2*lam2))(s,t))
show(S(s,t))
## Plotting the ellipes withe major-minor arix
origin = P*vector([x0,y0])
neworigin = point([(origin[0],origin[1])],color='green')
newxaxis = parametric_plot(origin+z*v1, (z,-15,15),color='green')
newyaxis = parametric_plot(origin+z*v2, (z,-15,15),color='green')
show(curve+neworigin+newxaxis+newyaxis+xaxis+yaxis,aspect_ratio=1)
  </input>

    <output>
    
  </output>
 </sage>
</example>

<example>
  <p>
   Consider the quadratic eqation given by <m>-x^2+4xy-y^2-30x,+y+20=0</m>. Use Sage to classify this and plot the 
   curve along with the transformed coordinates system. 
  </p>
  <sage>
    <input>
var('x,y')
var('u,v')
var('s,t')
var('z')
X = vector([x,y])
Y = vector([u,v])
a,b,c,d,e,f = -1,4,-1,-30,1,20
Q(x,y) = a*x^2+2*b*x*y+c*y^2+d*x+e*y+f
print('The curve is given by')
show(Q(x,y))
curve = implicit_plot(Q(x,y),(x,-5,10),(y,-5,10),gridlines=True,aspect_ratio=1)
xaxis=line([(-4,0),(4,0)],color='black')
yaxis=line([(0,-4),(0,4)],color='black')
show(curve+xaxis+yaxis)
## We define the associated matrix A
A= matrix([[a,b],[b,c]])
B= vector([d,e])
print('The quadratic in terms of matrices A and B')
show(expand(X.dot_product(A*X))+B.dot_product(X)+f)

## Orthogonal Diagonalization of the matrix A
print(f'The eigenvalues of A are {A.eigenvalues()}')
D,P = A.eigenmatrix_right();
lam1 = D[0,0]
lam2 = D[1,1]

## We normalize the eigenvectors and redefine P
v1 = P.columns()[0]/norm(P.columns()[0])
v2 = P.columns()[1]/norm(P.columns()[1])
P = column_matrix([v1,v2])
print('To check if PDP^{-1}=A')
print(P*D*P.inverse())

## The qudratic in terms of new coordinate system uv
R(u,v)=expand(Q.substitute(x=(P*Y)[0],y=(P*Y)[1])(u,v));
print(R(u,v))

## The translation vector
alpha = (B*P)[0]
beta = (B*P)[1]
x0=-alpha/(2*lam1)
y0=-beta/(2*lam2)
g = (alpha)^2/(4*lam1)+(beta)^2/(4*lam2)-f
show(g)

S(s,t)=expand(R.subs(u=s-alpha/(2*lam1),v=t-beta/(2*lam2))(s,t))
show(S(s,t))
## Plotting the ellipes withe major-minor arix
origin = P*vector([x0,y0])
neworigin = point([(origin[0],origin[1])],color='green')
newxaxis = parametric_plot(origin+z*v1, (z,-5,5),color='green')
newyaxis = parametric_plot(origin+z*v2, (z,-5,5),color='green')
show(curve+neworigin+newxaxis+newyaxis+xaxis+yaxis,aspect_ratio=1)
    </input>
    <output>
      
    </output>
  </sage>
</example>

<example>
  <statement>
    <p>
  Consider the quadratic equation <m>Q(x,y) = 3 \, x^{2} - 6 \, x y + 3 \, y^{2} - 6 \, x + 8 \, y + 5</m> and classify this 
  to  a conic section.
  </p>
  
  </statement>

  <solution>
    <p>
   The matrix associated with the quadratic part of the above equation is 
   <m>A = \left(\begin{array}{rr}
3 \amp -3 \\
-3 \amp 3
\end{array}\right)</m>. It is easy to check that the eigenvalues of <m>A</m> are <m>\lambda_1=6, \lambda_2=0</m>. Since one of the eigenvalues is 0, this curve is a parabola.  Let us draw this curve along with the tranformed orgini and the two new coordinate directions in Sage.
   </p>
<sage>
  <input>
  var('x,y')
var('u,v')
var('s,t')
var('z')
X = vector([x,y])
Y = vector([u,v])
a,b,c,d,e,f = 3,-3,3,-6,8,5
Q(x,y) = a*x^2+2*b*x*y+c*y^2+d*x+e*y+f
print('The curve is given by')
show(Q(x,y))
curve = implicit_plot(Q(x,y),(x,-5,5),(y,-5,5),gridlines=True,aspect_ratio=1)
xaxis=line([(-5,0),(5,0)],color='black')
yaxis=line([(0,-5),(0,5)],color='black')
show(curve+xaxis+yaxis)
## We define the associated matrix A
A= matrix([[a,b],[b,c]])
B= vector([d,e])
print('The quadratic in terms of matrices A and B')
show(expand(X.dot_product(A*X))+B.dot_product(X)+f)
## Orthogonal Diagonalization of the matrix A
print(f'The eigenvalues of A are {A.eigenvalues()}')
D,P = A.eigenmatrix_right();
lam1 = D[0,0]
lam2 = D[1,1]

## We normalize the eigenvectors and redefine P
v1 = P.columns()[0]/norm(P.columns()[0])
v2 = P.columns()[1]/norm(P.columns()[1])
P = column_matrix([v1,v2])
print('To check if PDP^{-1}=A')
print(P*D*P.inverse())

## The qudratic in terms of new coordinate system uv
R(u,v)=expand(Q.substitute(x=(P*Y)[0],y=(P*Y)[1])(u,v));
print(R(u,v))

## The translation vector
alpha = (B*P)[0]
beta = (B*P)[1]
x0=-alpha/(2*lam1)
y0=-beta
g = alpha^2/(4*lam1)-f

## Plotting the parabola
origin = P*vector([x0,y0])
neworigin = point([(origin[0],origin[1])],color='green')
newxaxis = parametric_plot(origin+z*v1, (z,-5,5),color='green')
newyaxis = parametric_plot(origin+z*v2, (z,-5,5),color='green')
show(curve+neworigin+newxaxis+newyaxis+xaxis+yaxis,aspect_ratio=1)
  </input>
  <output>
    
  </output>
</sage>   
   
  </solution>
</example>

<activity>
  <p>
    For given quadratic equation <m>Q(x,y)=ax^2+2bxy+cy^2+dx+ey+f=0</m>, write down the corresponding canonical conics by describing
    the new orgin <m>(x_0,y_0)</m>, and the new coordinate vectors by codisering different cases in a tabular form. 
  </p>
</activity>

</subsection>


<subsection xml:id="subsec-conic-suraces-3variables">
  <title>Classification of Quadratic Surfaces in Three Variables</title>
  <introduction>
    <p>
      The classification of quadratic equation in three varibale can be done in a very similar manner as we have seen in case of two variable <xref ref="subsec-6-3-quadratic-form"/>
    </p>
  </introduction>

  <p>
  A general quadratic equation in three variables is
<me>Q(x,y,z) = ax^2 + by^2 + cz^2 + 2dxy + 2eyz + 2fzx + gx + hy + iz + j=0
</me>
where <m>a,b,c,d,e,f,g,h,i,j \in \mathbb{R}</m>.  
</p>
<p>
In matrix form,
<me>
Q(\mathbf{x}) = \mathbf{x}^T A \mathbf{x} +  \mathbf{b}^T \mathbf{x} + j,
\quad 
\mathbf{x} = \begin{bmatrix} x \\ y \\ z \end{bmatrix}, \quad 
A = \begin{bmatrix} a \amp d \amp f \\ d \amp b \amp e \\ f \amp e \amp c \end{bmatrix}, \quad
\mathbf{b} = \begin{bmatrix} g \\ h \\ i \end{bmatrix}.
</me>

Since <m>A</m> is symmetric, there exists an orthogonal matrix <m>P</m> such that 
<me>
P^T A P = \Lambda = \operatorname{diag}(\lambda_1,\lambda_2,\lambda_3).
</me>
After an orthogonal change of variables <m>\mathbf{x} = P\mathbf{u}</m> and a translation 
to eliminate linear terms, the quadratic form reduces to the <em>canonical form</em>.
<me>
Q(u,v,w) = \lambda_1 u^2 + \lambda_2 v^2 + \lambda_3 w^2 + j = 0.
</me>
  </p>

 <p><alert>Classification of Quadrics</alert></p>
  
 
<p>
Depending on the signs of <m>\lambda_1, \lambda_2, \lambda_3</m>, we obtain the following surfaces:
</p>

<ol>
  <li>
    <p>
      <em>Ellipsoid: </em> All eigenvalues positive.
      <me>
         \frac{u^2}{a^2} + \frac{v^2}{b^2} + \frac{w^2}{c^2} = 1, a,b,c &gt; 0</me>. 
      </p>
         <sage>
          <input>
        ## Ellipsoid
        var('x y z')
        a, b, c = 2, 1.5, 1  # semi-axes

        ellipsoid = implicit_plot3d(x^2/a^2 + y^2/b^2 + z^2/c^2 - 1, 
                                      (x,-2,2), (y,-2,2), (z,-2,2), 
                                      color='gray', opacity=0.4)
        ellipsoid.show(frame=False,axes=True)
        </input>
          <output>
            
          </output>
        </sage>
  </li>
  <li>
    <p>
      <em>Hyperboloid of One Sheet: </em> Two positive eigenvalues, one negative.
      <me>
        \frac{u^2}{a^2} + \frac{v^2}{b^2} - \frac{w^2}{c^2} = 1.
      </me>
    </p>
    <sage>
      <input>
    ##Hyperboloid of One Sheets
var('x,y,z')
a, b, c = 1, 1, 1
hyperboloid1 = implicit_plot3d(x^2/a^2 + y^2/b^2 - z^2/c^2 - 1, 
                               (x,-2,2), (y,-2,2), (z,-3,3),
                               color='orange', opacity=0.4)
hyperboloid1.show(frame=False,axes=True,title='Hyperboloid of One Sheets')
      </input>
      <output>
        
      </output>
    </sage>
  </li>
  <li>
    <p>
       <em>Hyperboloid of Two Sheets:</em> One positive eigenvalue, two negative.
  <me>
  -\frac{u^2}{a^2} - \frac{v^2}{b^2} + \frac{w^2}{c^2} = 1.
  </me>
    </p>

    <sage>
      <input>
##Hyperboloid of Two Sheets
var('x,y,z')
a,b,c =1,1,1
hyperboloid2 = implicit_plot3d(-x^2/a^2 -y^2/b^2 + z^2/c^2 - 1, 
                               (x,-2,2), (y,-2,2), (z,-3,3),
                               color='green', opacity=0.6)
hyperboloid2.show(frame=False,axes=True)
      </input>
      <output>
        
      </output>
    </sage>
  </li>
  <li>
    <p>
      <em>Elliptic Cone: </em> Two positibve and one negative eigenvalues with no constant term.
  <me>
  \frac{u^2}{a^2} + \frac{v^2}{b^2} - \frac{w^2}{c^2} = 0.
  </me>
    </p>
    <sage>
      <input>
## Elliptic Cone
var('x,y,z')
a,b,c =1,1,1
elliptic_cone = implicit_plot3d(x^2/a^2 +y^2/b^2 - z^2/c^2, 
                               (x,-2,2), (y,-2,2), (z,-3,3),
                               color='green', opacity=0.6)
elliptic_cone.show(frame=False,axes=True)
      </input>
      <output>
        
      </output>
    </sage>
  </li>
  <li>
    <p>
  <em>Elliptic Paraboloid: (Bowl-shaped surface)</em> Two positive eigenvalues, one zero.
  <me>
  \frac{u^2}{a^2} + \frac{v^2}{b^2} = \frac{w}{c}.
  </me>
    </p>
    <sage>
      <input>
 ## Elliptic Paraboloid
var('x,y,z')
a,b,c=3,1,5
bowl = implicit_plot3d(x^2/a^2 + y^2/b^2-z/c, 
                (x,-2,2), (y,-2,2),(z,-2,2),
                color='green', opacity=0.6)
bowl.show(frame=False,axes=True)    
      </input>
      <output>
        
      </output>
    </sage>
  </li>
  <li>
    <p>
      <em>Hyperbolic Paraboloid: (Saddle Surface)</em> One positive eigenvalue, one negative, one zero.
  <me>
  \frac{u^2}{a^2} - \frac{v^2}{b^2} = \frac{w}{c}.
  </me>
    </p>
    <sage>
      <input>
    ## Hyperbolic Paraboloid (Saddle)
var('x,y,z')
a,b,c = 3,2,5
saddle = implicit_plot3d(x^2/a^2 - y^2/b^2-z/c, 
                (x,-2,2), (y,-2,2),(z,-2,2),
                color='green', opacity=0.6)
saddle.show(frame=False,axes=True)
      </input>
      <output>
        
      </output>
    </sage>
  </li>
  <li>
    <p>
   <em>Elliptic Cylinder:</em> Two positive eigenvalues, third zero.
  <me>
  \frac{u^2}{a^2} + \frac{v^2}{b^2} = 1.
  </me>
    </p>
    <sage>
      <input>
## Elliptic Cylinder
var('x,y,z')
a,b=2,1
ell_cyl = implicit_plot3d(x^2/a^2 + y^2/b^2-1, 
                (x,-4,4), (y,-2,2),(z,-2,2),
                color='green', opacity=0.6)
ell_cyl.show(frame=False,axes=True)
      </input>
      <output>
        
      </output>
    </sage>
  </li>
  <li>
    <p>
    <em>Hyperbolic Cylinder:  </em> One positive, one negative, third zero.
<me>
  \frac{u^2}{a^2} - \frac{v^2}{b^2} = 1.
</me>  
    </p>
  <sage>
    <input>
  ## Hyperbolic Cylinder
var('x,y,z')
a,b=2,1
hyp_cyl = implicit_plot3d(x^2/a^2 - y^2/b^2-1, 
                (x,-4,4), (y,-2,2),(z,-2,2),
                color='green', opacity=0.6)
hyp_cyl.show(frame=False,axes=True)    
    </input>
    <output>
      
    </output>
  </sage>
  </li>
  <li>
    <p>
      <em>Parabolic Cylinder:</em> Only one  nonzero eigenvalue.
  <me>
  \frac{u^2}{a^2} = \frac{v}{b}.
  </me>
    </p>
    <sage>
      <input>
     ## Parabolic Cylinder
var('x,y,z')
a,b=1,1
par_cyl = implicit_plot3d(x^2/a^2 - y/b-1, 
                (x,-2,2), (y,-2,2),(z,-2,2),
                color='green', opacity=0.6)
par_cyl.show(frame=False,axes=True)   
      </input>
      <output>
        
      </output>
    </sage>
  </li>
</ol>


</subsection>
  
</section>
