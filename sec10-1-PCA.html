<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US" dir="ltr">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Principal Component Analysis</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Linear Algebra with SageMath">
<meta property="book:author" content="Ajit Kumar">
<script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script><script>
var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  "tex": {
    "inlineMath": [
      [
        "\\(",
        "\\)"
      ]
    ],
    "tags": "none",
    "tagSide": "right",
    "tagIndent": ".8em",
    "packages": {
      "[+]": [
        "base",
        "extpfeil",
        "ams",
        "amscd",
        "color",
        "newcommand",
        "knowl"
      ]
    }
  },
  "options": {
    "ignoreHtmlClass": "tex2jax_ignore|ignore-math",
    "processHtmlClass": "process-math",
    "renderActions": {
      "findScript": [
        10,
        function (doc) {
            document.querySelectorAll('script[type^="math/tex"]').forEach(function(node) {
                var display = !!node.type.match(/; *mode=display/);
                var math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                var text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = {node: text, delim: '', n: 0};
                math.end = {node: text, delim: '', n: 0};
                doc.math.push(math);
            });
        },
        ""
      ]
    }
  },
  "chtml": {
    "scale": 0.98,
    "mtextInheritFont": true
  },
  "loader": {
    "load": [
      "input/asciimath",
      "[tex]/extpfeil",
      "[tex]/amscd",
      "[tex]/color",
      "[tex]/newcommand",
      "[pretext]/mathjaxknowl3.js"
    ],
    "paths": {
      "pretext": "_static/pretext/js/lib"
    }
  },
  "startup": {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
  }
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js" integrity="sha512-4xUl/d6D6THrAnXAwGajXkoWaeMNwEKK4iNfq5DotEbLPAfk6FSxSP3ydNxqDgCw1c/0Z1Jg6L8h2j+++9BZmg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lunr-pretext-search-index.js" async=""></script><script src="_static/pretext/js/pretext_search.js"></script><link href="_static/pretext/css/pretext_search.css" rel="stylesheet" type="text/css">
<script src="_static/pretext/js/lib/jquery.min.js"></script><script src="_static/pretext/js/lib/jquery.sticky.js"></script><script src="_static/pretext/js/lib/jquery.espy.min.js"></script><script src="_static/pretext/js/pretext.js"></script><script src="_static/pretext/js/pretext_add_on.js?x=1"></script><script src="_static/pretext/js/user_preferences.js"></script><script src="_static/pretext/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&amp;family=Noto+Serif:ital,wght@0,400;0,700;1,400;1,700&amp;family=Tinos:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.cdnfonts.com/css/dejavu-serif" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:opsz,wdth,wght@8..144,50..150,100..900&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wdth,wght@75..100,300..800&amp;display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
<link href="_static/pretext/css/pretext.css" rel="stylesheet" type="text/css">
<link href="_static/pretext/css/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="_static/pretext/css/shell_default.css" rel="stylesheet" type="text/css">
<link href="_static/pretext/css/banner_default.css" rel="stylesheet" type="text/css">
<link href="_static/pretext/css/navbar_default.css" rel="stylesheet" type="text/css">
<link href="_static/pretext/css/toc_default.css" rel="stylesheet" type="text/css">
<link href="_static/pretext/css/knowls_default.css" rel="stylesheet" type="text/css">
<link href="_static/pretext/css/style_oscarlevin.css" rel="stylesheet" type="text/css">
<link href="_static/pretext/css/colors_blue_red.css" rel="stylesheet" type="text/css">
<link href="_static/pretext/css/setcolors.css" rel="stylesheet" type="text/css">
<style>
#subsec-elmentary-row-operations-3 { counter-set: subsec-elmentary-row-operations-3 0; }
#subsec-elmentary-row-operations-3 > li::marker { content: ""counter(subsec-elmentary-row-operations-3,decimal)"."; }
#subsec-elmentary-row-operations-3 > li { counter-increment: subsec-elmentary-row-operations-3; }
#def-elementary-row-operations-2-1-2 { counter-set: def-elementary-row-operations-2-1-2 0; }
#def-elementary-row-operations-2-1-2 > li::marker { content: ""counter(def-elementary-row-operations-2-1-2,decimal)"."; }
#def-elementary-row-operations-2-1-2 > li { counter-increment: def-elementary-row-operations-2-1-2; }
#subsec-elmentary-row-operations-8-14-1 { counter-set: subsec-elmentary-row-operations-8-14-1 0; }
#subsec-elmentary-row-operations-8-14-1 > li::marker { content: ""counter(subsec-elmentary-row-operations-8-14-1,decimal)"."; }
#subsec-elmentary-row-operations-8-14-1 > li { counter-increment: subsec-elmentary-row-operations-8-14-1; }
#subsec-elmentary-row-operations-15-1-1 { counter-set: subsec-elmentary-row-operations-15-1-1 0; }
#subsec-elmentary-row-operations-15-1-1 > li::marker { content: ""counter(subsec-elmentary-row-operations-15-1-1,decimal)"."; }
#subsec-elmentary-row-operations-15-1-1 > li { counter-increment: subsec-elmentary-row-operations-15-1-1; }
#def-echelon-form-5 { counter-set: def-echelon-form-5 0; }
#def-echelon-form-5 > li::marker { content: ""counter(def-echelon-form-5,decimal)"."; }
#def-echelon-form-5 > li { counter-increment: def-echelon-form-5; }
#sec-row-echelon-5-3 { counter-set: sec-row-echelon-5-3 0; }
#sec-row-echelon-5-3 > li::marker { content: ""counter(sec-row-echelon-5-3,decimal)"."; }
#sec-row-echelon-5-3 > li { counter-increment: sec-row-echelon-5-3; }
#alg-gaussian-elimination-2 { counter-set: alg-gaussian-elimination-2 0; }
#alg-gaussian-elimination-2 > li::marker { content: ""counter(alg-gaussian-elimination-2,decimal)"."; }
#alg-gaussian-elimination-2 > li { counter-increment: alg-gaussian-elimination-2; }
#sec1-4-matrix-rank-5-2 { counter-set: sec1-4-matrix-rank-5-2 0; }
#sec1-4-matrix-rank-5-2 > li::marker { content: ""counter(sec1-4-matrix-rank-5-2,decimal)"."; }
#sec1-4-matrix-rank-5-2 > li { counter-increment: sec1-4-matrix-rank-5-2; }
#thm-nosol-rank-2-1-5 { counter-set: thm-nosol-rank-2-1-5 0; }
#thm-nosol-rank-2-1-5 > li::marker { content: ""counter(thm-nosol-rank-2-1-5,decimal)"."; }
#thm-nosol-rank-2-1-5 > li { counter-increment: thm-nosol-rank-2-1-5; }
#sec1-6-LU-5 { counter-set: sec1-6-LU-5 0; }
#sec1-6-LU-5 > li::marker { content: ""counter(sec1-6-LU-5,decimal)"."; }
#sec1-6-LU-5 > li { counter-increment: sec1-6-LU-5; }
#sec1-6-LU-6-11-1 { counter-set: sec1-6-LU-6-11-1 0; }
#sec1-6-LU-6-11-1 > li::marker { content: ""counter(sec1-6-LU-6-11-1,decimal)"."; }
#sec1-6-LU-6-11-1 > li { counter-increment: sec1-6-LU-6-11-1; }
#ch1-exer-2-1 { counter-set: ch1-exer-2-1 0; }
#ch1-exer-2-1 > li::marker { content: ""counter(ch1-exer-2-1,decimal)"."; }
#ch1-exer-2-1 > li { counter-increment: ch1-exer-2-1; }
#ch1-exer-2-1-3-1-1 { counter-set: ch1-exer-2-1-3-1-1 0; }
#ch1-exer-2-1-3-1-1 > li::marker { content: "("counter(ch1-exer-2-1-3-1-1,lower-alpha)")"; }
#ch1-exer-2-1-3-1-1 > li { counter-increment: ch1-exer-2-1-3-1-1; }
#sec2-0-intro-10-2-1-1 { counter-set: sec2-0-intro-10-2-1-1 0; }
#sec2-0-intro-10-2-1-1 > li::marker { content: ""counter(sec2-0-intro-10-2-1-1,decimal)"."; }
#sec2-0-intro-10-2-1-1 > li { counter-increment: sec2-0-intro-10-2-1-1; }
#sec2-1-LinSpan-5-1-2-1 { counter-set: sec2-1-LinSpan-5-1-2-1 0; }
#sec2-1-LinSpan-5-1-2-1 > li::marker { content: ""counter(sec2-1-LinSpan-5-1-2-1,decimal)"."; }
#sec2-1-LinSpan-5-1-2-1 > li { counter-increment: sec2-1-LinSpan-5-1-2-1; }
#sec2-1-matrix-spaces-2-5 { counter-set: sec2-1-matrix-spaces-2-5 0; }
#sec2-1-matrix-spaces-2-5 > li::marker { content: ""counter(sec2-1-matrix-spaces-2-5,decimal)"."; }
#sec2-1-matrix-spaces-2-5 > li { counter-increment: sec2-1-matrix-spaces-2-5; }
#sec-2-2-remrak2-1 { counter-set: sec-2-2-remrak2-1 0; }
#sec-2-2-remrak2-1 > li::marker { content: ""counter(sec-2-2-remrak2-1,decimal)"."; }
#sec-2-2-remrak2-1 > li { counter-increment: sec-2-2-remrak2-1; }
#sec-xxx-2-3 { counter-set: sec-xxx-2-3 0; }
#sec-xxx-2-3 > li::marker { content: ""counter(sec-xxx-2-3,decimal)"."; }
#sec-xxx-2-3 > li { counter-increment: sec-xxx-2-3; }
#sec4-1-VS-3-1-1-6 { counter-set: sec4-1-VS-3-1-1-6 0; }
#sec4-1-VS-3-1-1-6 > li::marker { content: ""counter(sec4-1-VS-3-1-1-6,decimal)"."; }
#sec4-1-VS-3-1-1-6 > li { counter-increment: sec4-1-VS-3-1-1-6; }
#thm-basis-equiv-1-1-3 { counter-set: thm-basis-equiv-1-1-3 0; }
#thm-basis-equiv-1-1-3 > li::marker { content: ""counter(thm-basis-equiv-1-1-3,decimal)"."; }
#thm-basis-equiv-1-1-3 > li { counter-increment: thm-basis-equiv-1-1-3; }
#sec4-5-VS-Ex-2 { counter-set: sec4-5-VS-Ex-2 0; }
#sec4-5-VS-Ex-2 > li::marker { content: ""counter(sec4-5-VS-Ex-2,decimal)"."; }
#sec4-5-VS-Ex-2 > li { counter-increment: sec4-5-VS-Ex-2; }
#sec5-0-eigen-17-2-1 { counter-set: sec5-0-eigen-17-2-1 0; }
#sec5-0-eigen-17-2-1 > li::marker { content: ""counter(sec5-0-eigen-17-2-1,decimal)"."; }
#sec5-0-eigen-17-2-1 > li { counter-increment: sec5-0-eigen-17-2-1; }
#sec5-0-eigen-17-4-1-1 { counter-set: sec5-0-eigen-17-4-1-1 0; }
#sec5-0-eigen-17-4-1-1 > li::marker { content: ""counter(sec5-0-eigen-17-4-1-1,decimal)"."; }
#sec5-0-eigen-17-4-1-1 > li { counter-increment: sec5-0-eigen-17-4-1-1; }
#sec5-0-eigen-18-5-2 { counter-set: sec5-0-eigen-18-5-2 0; }
#sec5-0-eigen-18-5-2 > li::marker { content: ""counter(sec5-0-eigen-18-5-2,decimal)"."; }
#sec5-0-eigen-18-5-2 > li { counter-increment: sec5-0-eigen-18-5-2; }
#sec-eigen-2 { counter-set: sec-eigen-2 0; }
#sec-eigen-2 > li::marker { content: ""counter(sec-eigen-2,decimal)"."; }
#sec-eigen-2 > li { counter-increment: sec-eigen-2; }
#sec6-0-orthogonality-8-1-1 { counter-set: sec6-0-orthogonality-8-1-1 0; }
#sec6-0-orthogonality-8-1-1 > li::marker { content: ""counter(sec6-0-orthogonality-8-1-1,decimal)"."; }
#sec6-0-orthogonality-8-1-1 > li { counter-increment: sec6-0-orthogonality-8-1-1; }
#sec7-0-InnerProduct-3-3 { counter-set: sec7-0-InnerProduct-3-3 0; }
#sec7-0-InnerProduct-3-3 > li::marker { content: ""counter(sec7-0-InnerProduct-3-3,decimal)"."; }
#sec7-0-InnerProduct-3-3 > li { counter-increment: sec7-0-InnerProduct-3-3; }
#sec7-0-InnerProduct-5-1-1-7 { counter-set: sec7-0-InnerProduct-5-1-1-7 0; }
#sec7-0-InnerProduct-5-1-1-7 > li::marker { content: ""counter(sec7-0-InnerProduct-5-1-1-7,decimal)"."; }
#sec7-0-InnerProduct-5-1-1-7 > li { counter-increment: sec7-0-InnerProduct-5-1-1-7; }
#sec7-2-Exer-3-1 { counter-set: sec7-2-Exer-3-1 0; }
#sec7-2-Exer-3-1 > li::marker { content: ""counter(sec7-2-Exer-3-1,decimal)"."; }
#sec7-2-Exer-3-1 > li { counter-increment: sec7-2-Exer-3-1; }
#sec9-0-SVD-4-2-1-1-6 { counter-set: sec9-0-SVD-4-2-1-1-6 0; }
#sec9-0-SVD-4-2-1-1-6 > li::marker { content: ""counter(sec9-0-SVD-4-2-1-1-6,decimal)"."; }
#sec9-0-SVD-4-2-1-1-6 > li { counter-increment: sec9-0-SVD-4-2-1-1-6; }
#sec9-0-SVD-4-10-1 { counter-set: sec9-0-SVD-4-10-1 0; }
#sec9-0-SVD-4-10-1 > li::marker { content: ""counter(sec9-0-SVD-4-10-1,decimal)"."; }
#sec9-0-SVD-4-10-1 > li { counter-increment: sec9-0-SVD-4-10-1; }
</style>
</head>
<body id="changeme" class="pretext book ignore-math">
<a class="assistive" href="#ptx-content">Skip to main content</a><header id="ptx-masthead" class="ptx-masthead"><div class="ptx-banner">
<a id="logo-link" class="logo-link" target="_blank" href=""></a><div class="title-container">
<h1 class="heading"><a href="linalg-pretext-book.html"><span class="title">Linear Algebra with SageMath:</span> <span class="subtitle">A Gentle Introduction</span></a></h1>
<p class="byline">Ajit Kumar</p>
</div>
</div></header><nav id="ptx-navbar" class="ptx-navbar navbar"><button class="toc-toggle button" title="Contents"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5d2;</span><span class="name">Contents</span></button><div class="searchbox">
<div class="searchwidget"><button id="searchbutton" class="searchbutton button" type="button" title="Search book"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe8b6;</span><span class="name">Search Book</span></button></div>
<div id="searchresultsplaceholder" class="searchresultsplaceholder" style="display: none">
<div class="search-results-controls">
<input aria-label="Search term" id="ptxsearch" class="ptxsearch" type="text" name="terms" placeholder="Search term"><button title="Close search" id="closesearchresults" class="closesearchresults"><span class="material-symbols-outlined">close</span></button>
</div>
<h2 class="search-results-heading">Search Results: </h2>
<div id="searchempty" class="searchempty"><span>No results.</span></div>
<ol id="searchresults" class="searchresults"></ol>
</div>
</div>
<span class="nav-other-controls"></span><span class="treebuttons"><a class="previous-button button" href="chap10-PCA.html" title="Previous"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cb;</span><span class="name">Prev</span></a><a class="up-button button" href="chap10-PCA.html" title="Up"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5ce;</span><span class="name">Up</span></a><a class="next-button button" href="backmatter.html" title="Next"><span class="name">Next</span><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cc;</span></a></span></nav><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(    \newcommand{\Loadedframemethod}{default}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\inner}[2]{\left\langle #1,#2\right\rangle}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\normx}[1]{\left\Vert#1\right\Vert}
\newcommand{\partd}[2]{\dfrac{\partial #1}{\partial #2}}
\newcommand{\innprod}[2]{\left\lt #1,#2\right&gt;}
\def\rank{{ rank\,}}
\newcommand{\ds}{\displaystyle}

\def\diag{{ diag\,}}
\def\proj{{ proj\,}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<div class="ptx-page">
<div id="ptx-sidebar" class="ptx-sidebar"><nav id="ptx-toc" class="ptx-toc depth2"><ul class="structural contains-active toc-item-list">
<li class="toc-item toc-frontmatter"><div class="toc-title-box"><a href="frontmatter.html" class="internal"><span class="title">Front Matter</span></a></div></li>
<li class="toc-item toc-chapter">
<div class="toc-title-box"><a href="chap1-lineq.html" class="internal"><span class="codenumber">1</span> <span class="title">System of Linear Equations</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-elementary-operations.html" class="internal"><span class="codenumber">1.1</span> <span class="title">Elementary Row Operations</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-elementary-operations.html#subsec-elmentary-row-operations" class="internal"><span class="codenumber">1.1.1</span> <span class="title">Elmentary Row Operations</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-elementary-operations.html#subsec-Matrix-inverse-using-rref" class="internal"><span class="codenumber">1.1.2</span> <span class="title">Matrix Inversion via Elementary Row Operations</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec-col-operations.html" class="internal"><span class="codenumber">1.2</span> <span class="title">Elementary Column Operations</span></a></div></li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-echelon-form.html" class="internal"><span class="codenumber">1.3</span> <span class="title">Echelon Forms</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-echelon-form.html#sec-row-echelon" class="internal"><span class="codenumber">1.3.1</span> <span class="title">Row Echelon Form</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-echelon-form.html#subsec-Gaussian-Elimination" class="internal"><span class="codenumber">1.3.2</span> <span class="title">Gaussian Elimination Method</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-echelon-form.html#subsec-Gauss-Jordan-Method" class="internal"><span class="codenumber">1.3.3</span> <span class="title">Gauss-Jordan elimination method</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec1-4-matrix-rank.html" class="internal"><span class="codenumber">1.4</span> <span class="title">Rank of Matrices</span></a></div></li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec-hom-system.html" class="internal"><span class="codenumber">1.5</span> <span class="title">Homogeneous System of Linear Equations</span></a></div></li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec1-6-LU.html" class="internal"><span class="codenumber">1.6</span> <span class="title"><span class="process-math">\(LU\)</span>-Facotorization</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec1-6-LU.html#subsec-solving-system-LU" class="internal"><span class="codenumber">1.6.1</span> <span class="title">Solving system of equations using LU factorization</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec1-6-LU.html#subsec-lu-sage" class="internal"><span class="codenumber">1.6.2</span> <span class="title"><span class="process-math">\(LU\)</span>-factorization in Sage</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec1-6-LU.html#subsec-" class="internal"><span class="codenumber">1.6.3</span> <span class="title">User defined functions for DooLitlte and Crout’s Methods</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="ch1-exer.html" class="internal"><span class="codenumber">1.7</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-chapter">
<div class="toc-title-box"><a href="chap2-Rn-Space.html" class="internal"><span class="codenumber">2</span> <span class="title"><span class="process-math">\(\R^n\)</span> as a Vector Space</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec2-0-intro.html" class="internal"><span class="codenumber">2.1</span> <span class="title">Introduction</span></a></div></li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec2-1-LinSpan.html" class="internal"><span class="codenumber">2.2</span> <span class="title">Linear Spans</span></a></div></li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec-2-2-LI.html" class="internal"><span class="codenumber">2.3</span> <span class="title">Linear Dependence</span></a></div></li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec-2-3-basis-dimension.html" class="internal"><span class="codenumber">2.4</span> <span class="title">Basis and Dimension</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec-2-3-basis-dimension.html#sec2-3-change-of-basis" class="internal"><span class="codenumber">2.4.1</span> <span class="title">Change of bases.</span></a></div></li></ul>
</li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec2-4-Sage.html" class="internal"><span class="codenumber">2.5</span> <span class="title">Sage Computations</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-chapter">
<div class="toc-title-box"><a href="chap3-LT.html" class="internal"><span class="codenumber">3</span> <span class="title">Linear Transformations</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec3-1-LT.html" class="internal"><span class="codenumber">3.1</span> <span class="title">Introduction</span></a></div></li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec3-2-LT.html" class="internal"><span class="codenumber">3.2</span> <span class="title">Linear maps from <span class="process-math">\(\R^n\)</span> to <span class="process-math">\(\R^m\)</span></span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec3-2-LT.html#sec3-2-LT-16" class="internal"><span class="codenumber">3.2.1</span> <span class="title">Composition of linear transformations</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec3-2-LT.html#sec3-2-LT-17" class="internal"><span class="codenumber">3.2.2</span> <span class="title">Matrix of Change of basis</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec3-3-LT.html" class="internal"><span class="codenumber">3.3</span> <span class="title">Reflections and Projections</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec3-3-LT.html#sec3-3-LT-3" class="internal"><span class="codenumber">3.3.1</span> <span class="title">Reflections in <span class="process-math">\(\R^2\)</span></span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec3-3-LT.html#sec3-3-LT-4" class="internal"><span class="codenumber">3.3.2</span> <span class="title">Projections in <span class="process-math">\(\R^2\)</span></span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec3-3-LT.html#sec3-3-LT-5" class="internal"><span class="codenumber">3.3.3</span> <span class="title">Projection and Reflection in <span class="process-math">\(\R^3\)</span></span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec-xxx.html" class="internal"><span class="codenumber">3.4</span> <span class="title">Geometry of Linear Transformations</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-chapter">
<div class="toc-title-box"><a href="chap4-Vector-Space.html" class="internal"><span class="codenumber">4</span> <span class="title">Vector Spaces</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec4-1-VS.html" class="internal"><span class="codenumber">4.1</span> <span class="title">Introduction</span></a></div></li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec4-1-abstract-vs.html" class="internal"><span class="codenumber">4.2</span> <span class="title">Vector Subspaces</span></a></div></li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec4-2-linspan-VS.html" class="internal"><span class="codenumber">4.3</span> <span class="title">Linear Span</span></a></div></li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec4-3-LI-VS.html" class="internal"><span class="codenumber">4.4</span> <span class="title">Linear dependence and independence</span></a></div></li>
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec4-5-basis-dim-VS.html" class="internal"><span class="codenumber">4.5</span> <span class="title">Basis and dimension</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec4-5-basis-dim-VS.html#sec4-5-basis-dim-VS-17" class="internal"><span class="codenumber">4.5.1</span> <span class="title">How to find a basis of a finite dimensional vector space?</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec4-5-basis-dim-VS.html#sec4-5-basis-dim-VS-18" class="internal"><span class="codenumber">4.5.2</span> <span class="title">Lagrange Interpolation</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec4-5-basis-dim-VS.html#sec4-5-basis-dim-VS-25" class="internal"><span class="codenumber">4.5.3</span> <span class="title">Dimension Formula</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec4-5-VS-Ex.html" class="internal"><span class="codenumber">4.6</span> <span class="title">Exercise Set</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-chapter">
<div class="toc-title-box"><a href="chap5-Eigen.html" class="internal"><span class="codenumber">5</span> <span class="title">Eigenvalues and Eigenvectors</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec5-0-eigen.html" class="internal"><span class="codenumber">5.1</span> <span class="title">Introduction</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec5-0-eigen.html#sec5-0-eigen-17" class="internal"><span class="codenumber">5.1.1</span> <span class="title">Properties of Eigenvalues and Eigenvectors</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec5-0-eigen.html#sec5-0-eigen-18" class="internal"><span class="codenumber">5.1.2</span> <span class="title">Positive definite matrix</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec5-0-eigen.html#sec5-0-eigen-19" class="internal"><span class="codenumber">5.1.3</span> <span class="title">Diagonalization</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec5-0-eigen.html#sec-eigen" class="internal"><span class="codenumber">5.1.4</span> <span class="title">Exercises on Eigenvalues and Eigenvectors</span></a></div></li>
</ul>
</li></ul>
</li>
<li class="toc-item toc-chapter">
<div class="toc-title-box"><a href="chap5-orthogonality.html" class="internal"><span class="codenumber">6</span> <span class="title">Orthogonality</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec6-0-orthogonality.html" class="internal"><span class="codenumber">6.1</span> <span class="title">Orthogonality</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec6-0-orthogonality.html#sec6-0-orthogonality-9" class="internal"><span class="codenumber">6.1.1</span> <span class="title">What is an advantage of having an orthonormal basis?</span></a></div></li></ul>
</li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec6-1-GramSchmidt.html" class="internal"><span class="codenumber">6.2</span> <span class="title">Gram-Schmidt Orthogonalization Process</span></a></div></li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec6-2.html" class="internal"><span class="codenumber">6.3</span> <span class="title">Orthogonal Complements</span></a></div></li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec6-3.html" class="internal"><span class="codenumber">6.4</span> <span class="title">Orthogonal Diagonalizations</span></a></div></li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec6-4.html" class="internal"><span class="codenumber">6.5</span> <span class="title">QR-Factorization</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-chapter">
<div class="toc-title-box"><a href="chap5-inner-product.html" class="internal"><span class="codenumber">7</span> <span class="title">Inner Product</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec7-0-InnerProduct.html" class="internal"><span class="codenumber">7.1</span> <span class="title">Inner Product</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec7-0-InnerProduct.html#sec7-0-InnerProduct-31" class="internal"><span class="codenumber">7.1.1</span> <span class="title">Projection onto a subspace</span></a></div></li></ul>
</li>
<li class="toc-item toc-section"><div class="toc-title-box"><a href="sec7-2-Exer.html" class="internal"><span class="codenumber">7.2</span> <span class="title">Exercise Set</span></a></div></li>
</ul>
</li>
<li class="toc-item toc-chapter">
<div class="toc-title-box"><a href="chap8-Least-Square.html" class="internal"><span class="codenumber">8</span> <span class="title">Least Square Problems</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec8-0-LSTSQ.html" class="internal"><span class="codenumber">8.1</span> <span class="title">Linear Least Square Problems</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec8-0-LSTSQ.html#sec8-0-LSTSQ-16" class="internal"><span class="codenumber">8.1.1</span> <span class="title">Fitting a polynomial to the data set</span></a></div></li></ul>
</li></ul>
</li>
<li class="toc-item toc-chapter">
<div class="toc-title-box"><a href="chap9-SVD.html" class="internal"><span class="codenumber">9</span> <span class="title">Singular Value Decomposition</span></a></div>
<ul class="structural toc-item-list"><li class="toc-item toc-section">
<div class="toc-title-box"><a href="sec9-0-SVD.html" class="internal"><span class="codenumber">9.1</span> <span class="title">Singular Value Decomposition</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec9-0-SVD.html#sec9-0-SVD-3" class="internal"><span class="codenumber">9.1.1</span> <span class="title">Singular Value Decomposition Theorem</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec9-0-SVD.html#sec9-0-SVD-4" class="internal"><span class="codenumber">9.1.2</span> <span class="title">Pseudoinverse using SVD</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec9-0-SVD.html#sec9-0-SVD-5" class="internal"><span class="codenumber">9.1.3</span> <span class="title">Geometry of SVD</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec9-0-SVD.html#sec9-0-SVD-6" class="internal"><span class="codenumber">9.1.4</span> <span class="title">Image Compression using SVD</span></a></div></li>
</ul>
</li></ul>
</li>
<li class="toc-item toc-chapter contains-active">
<div class="toc-title-box"><a href="chap10-PCA.html" class="internal"><span class="codenumber">10</span> <span class="title">Principal Component Analysis</span></a></div>
<ul class="structural toc-item-list contains-active"><li class="toc-item toc-section active">
<div class="toc-title-box"><a href="sec10-1-PCA.html" class="internal"><span class="codenumber">10.1</span> <span class="title">Principal Component Analysis</span></a></div>
<ul class="structural toc-item-list">
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec10-1-PCA.html#sec10-1-PCA-3" class="internal"><span class="codenumber">10.1.1</span> <span class="title">Mathematics behind PCA</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec10-1-PCA.html#sec10-1-PCA-4" class="internal"><span class="codenumber">10.1.2</span> <span class="title">Applications of PCA</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec10-1-PCA.html#sec10-1-PCA-5" class="internal"><span class="codenumber">10.1.3</span> <span class="title">Image compression with PCA</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec10-1-PCA.html#sec10-1-PCA-6" class="internal"><span class="codenumber">10.1.4</span> <span class="title">Relation Between SVD and PCA</span></a></div></li>
<li class="toc-item toc-subsection"><div class="toc-title-box"><a href="sec10-1-PCA.html#sec10-1-PCA-7" class="internal"><span class="codenumber">10.1.5</span> <span class="title">Exercise Set</span></a></div></li>
</ul>
</li></ul>
</li>
<li class="toc-item toc-backmatter"><div class="toc-title-box"><a href="backmatter.html" class="internal"><span class="title">Backmatter</span></a></div></li>
</ul></nav></div>
<main class="ptx-main"><div id="ptx-content" class="ptx-content"><section class="section" id="sec10-1-PCA"><h2 class="heading hide-type">
<span class="type">Section</span><span class="space"> </span><span class="codenumber">10.1</span><span class="space"> </span><span class="title">Principal Component Analysis</span>
</h2>
<section class="introduction" id="sec10-1-PCA-2"><div class="para" id="sec10-1-PCA-2-1">Large datasets with a large number of features/variables are very common and widespread. Interpreting such a large datasets is very complex task. In order to interpret such datasets one requires a method that reduces the dimension/features drastically, at the same time most of the information in the dateset is preserved. The principal component analysis (PCA) is one of the most widely used dimensionality reduction techniques. The main idea of PCA is to reduce the dimensionality in the datasets while preserving much of the variability as much as possible. It does so by creating a new set of uncorrelated variables that successfully maximize the variance. Finding such new variables also known as principal components reduces the problem to solving an eigenvalue-eigenvector problem.</div> <div class="para" id="sec10-1-PCA-2-2">Let us look at the set of points in the plane, (data with two features) in the <a href="sec10-1-PCA.html#fig_pca1" class="xref" data-knowl="./knowl/xref/fig_pca1.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.1">figure 10.1.1</a>. In this case the data has maximum spread or variability along the <span class="process-math">\(y\)</span>-axis. Thus if we project, the points onto the <span class="process-math">\(y\)</span>-axis, the variability in the data can be captured. In particular, we can ignore the <span class="process-math">\(x\)</span>-coordinates. On the other hand if we look at the set of points in the <a href="sec10-1-PCA.html#fig_pca2" class="xref" data-knowl="./knowl/xref/fig_pca2.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.2">figure 10.1.2</a>, maximum spread or variability lies along the <span class="process-math">\(x\)</span>-axis. Thus if we project, the points onto the <span class="process-math">\(x\)</span>-axis, the variability in the data can be captured. In particular, we can ignore the <span class="process-math">\(y\)</span>-coordinates. Thus in these two examples, we are able to reduce the dimension by 1.</div> <figure class="figure figure-like" id="fig_pca1"><div class="image-box" style="width: 45%; margin-left: 27.5%; margin-right: 27.5%;"><img src="external/images/PCA-Fig2.PNG" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.1<span class="period">.</span></span><span class="space"> </span>Variability along <span class="process-math">\(y\)</span>-axis</figcaption></figure> <figure class="figure figure-like" id="fig_pca2"><div class="image-box" style="width: 45%; margin-left: 27.5%; margin-right: 27.5%;"><img src="external/images/PCA-Fig2.PNG" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.2<span class="period">.</span></span><span class="space"> </span>ariability along <span class="process-math">\(x\)</span>-axis</figcaption></figure> <div class="para" id="sec10-1-PCA-2-5">Now suppose we have 12 points as show in the <a href="sec10-1-PCA.html#fig_pca3" class="xref" data-knowl="./knowl/xref/fig_pca3.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.3">Figure 10.1.3</a> again in <span class="process-math">\(\R^2\text{,}\)</span> that is having two features/dimensions. The spread of this data seems to be not along <span class="process-math">\(x\)</span>-axis but roughly along the axis as shown in the <a href="sec10-1-PCA.html#fig_pca4" class="xref" data-knowl="./knowl/xref/fig_pca4.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.4">Figure 10.1.4</a>, that is, along the vector <span class="process-math">\(u_1\text{.}\)</span> So if we project these points on the line along <span class="process-math">\(u_1\)</span> as shown in the <a href="sec10-1-PCA.html#fig_pca4" class="xref" data-knowl="./knowl/xref/fig_pca4.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.4">Figure 10.1.4</a>, we will have maximum spread or variation of the data. Thus <span class="process-math">\(u_1\)</span> is the new axis along which the data has maximum variation.</div> <figure class="figure figure-like" id="fig_pca3"><div class="image-box" style="width: 45%; margin-left: 27.5%; margin-right: 27.5%;"><img src="external/images/PCA-Fig3.PNG" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.3<span class="period">.</span></span><span class="space"> </span>Data with two features.</figcaption></figure> <figure class="figure figure-like" id="fig_pca4"><div class="image-box" style="width: 45%; margin-left: 27.5%; margin-right: 27.5%;"><img src="external/images/PCA-Fig4.PNG" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.4<span class="period">.</span></span><span class="space"> </span>Variability along vector <span class="process-math">\(u_1\text{.}\)</span></figcaption></figure> <div class="para" id="sec10-1-PCA-2-8">Next if one carefully looks into the data points, one can see that the data also has some dispersion or variation along the line given by the direction <span class="process-math">\(u_2\)</span> as shown in the <a href="sec10-1-PCA.html#fig_pca5" class="xref" data-knowl="./knowl/xref/fig_pca5.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.5">Figure 10.1.5</a> and which is not captured by the line along <span class="process-math">\(u_1\text{.}\)</span> In a way, we need to create another axis which is perpendicular to the 1st one.</div> <div class="para" id="sec10-1-PCA-2-9">Thus we have two perpendicular coordinate axes or a new coordinates system along which all the variations in the data can be captured. In this case, maximum variation along <span class="process-math">\(u_1\)</span> and second maximum along <span class="process-math">\(u_2\text{.}\)</span> Here <span class="process-math">\(u_1\)</span> is called the first principal direction and <span class="process-math">\(u_2\)</span> is called the second principal direction. Thus we can work with new coordinate axes and forget about the original <span class="process-math">\(x\)</span> and <span class="process-math">\(y\)</span>-axes as show in the <a href="sec10-1-PCA.html#fig_pca6" class="xref" data-knowl="./knowl/xref/fig_pca6.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.6">Figure 10.1.6</a>. We can even rotate the new coordinate system that coincides with original <span class="process-math">\(x\)</span> and <span class="process-math">\(y\)</span>-axes.</div> <figure class="figure figure-like" id="fig_pca5"><div class="image-box" style="width: 45%; margin-left: 27.5%; margin-right: 27.5%;"><img src="external/images/PCA-Fig5.PNG" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.5<span class="period">.</span></span><span class="space"> </span>1st and 2nd principal components <span class="process-math">\(u_1\)</span> and <span class="process-math">\(u_2\text{.}\)</span></figcaption></figure> <figure class="figure figure-like" id="fig_pca6"><div class="image-box" style="width: 45%; margin-left: 27.5%; margin-right: 27.5%;"><img src="external/images/PCA-Fig6.PNG" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.6<span class="period">.</span></span><span class="space"> </span>1st and 2nd principal components <span class="process-math">\(u_1\)</span> and <span class="process-math">\(u_2\text{.}\)</span></figcaption></figure> <div class="para" id="sec10-1-PCA-2-12">The above two examples, geometrically explains the essence of PCA. The idea is to project the original high dimensional data to a new coordinate system and choose only first we coordinates axes also called principal components. How many principal component to be taken depends upon how much variation we wish to capture.</div></section><section class="subsection" id="sec10-1-PCA-3"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">10.1.1</span><span class="space"> </span><span class="title">Mathematics behind PCA</span>
</h3>
<div class="para logical" id="sec10-1-PCA-3-2">
<div class="para">Let us assume that we have a data which has <span class="process-math">\(d\)</span> features and there are <span class="process-math">\(n\)</span> of them. This data can be represented by a <span class="process-math">\(n\times d\)</span> matrix, say <span class="process-math">\(X\text{.}\)</span> Thus</div>
<div class="displaymath process-math">
\begin{equation*}
X = \begin{bmatrix}x_{11} \amp  x_{12} \amp  \cdots \amp  x_{1d}\\ x_{21} \amp  x_{22} \amp  \cdots \amp  x_{2d}\\ \vdots \amp  \vdots \amp  \ddots \amp  \vdots\\ x_{n1} \amp  x_{n2} \amp  \cdots \amp  x_{nd} \end{bmatrix}\text{.}
\end{equation*}
</div>
<div class="para">Thus each columns of <span class="process-math">\(X\)</span> represents a feature and there are <span class="process-math">\(n\)</span> samples for each feature.</div>
</div>
<div class="para" id="sec10-1-PCA-3-3">Now we are looking for an unit vector <span class="process-math">\(u_1\)</span> and we wish to project the data onto <span class="process-math">\(u_1\)</span> such that the variance of the projected data is maximum.</div>
<div class="para logical" id="sec10-1-PCA-3-4">
<div class="para">Before we explain that in generality, let us look at what is meaning of projection of data in 2 dimension (that is in <span class="process-math">\(\R^2\)</span>) on an unit vector. Suppose <span class="process-math">\(u=(a,b)\)</span> is an unit vector ad <span class="process-math">\(p_1=(x_1,y_1)\)</span> be a point/vector in <span class="process-math">\(\R^2\text{.}\)</span> Then</div>
<div class="displaymath process-math">
\begin{equation*}
\proj_u(p_1)=\frac{p_1\cdot u}{\norm{u}^2}u=(x_1a+x_2b)u\text{.}
\end{equation*}
</div>
</div>
<div class="para logical" id="sec10-1-PCA-3-5">
<div class="para">The length of the projection is <span class="process-math">\(p_1x_2+p_2x_2\text{.}\)</span> If we have another point, say <span class="process-math">\(p_2 =(x_2,y_2)\text{,}\)</span> then the projection of both these points can be captured as</div>
<div class="displaymath process-math">
\begin{equation*}
\begin{bmatrix}x_1 \amp  x_2 \\y_1 \amp  y_2 \end{bmatrix}  \begin{bmatrix}a\\b \end{bmatrix}  = Xu\text{.}
\end{equation*}
</div>
</div>
<div class="para logical" id="sec10-1-PCA-3-6">
<div class="para">Thus in general the projection of data <span class="process-math">\(X\)</span> which is <span class="process-math">\(n\times p\)</span> matrix onto a unit vector <span class="process-math">\(u_1=\begin{bmatrix}u_{11}\amp  u_{12}\amp \cdots \amp  u_{1d} \end{bmatrix} ^T\)</span> is</div>
<div class="displaymath process-math">
\begin{equation*}
X = \begin{bmatrix}x_{11} \amp  x_{12} \amp  \cdots \amp  x_{1d}\\ x_{21} \amp  x_{22} \amp  \cdots \amp  x_{2d}\\ \vdots \amp  \vdots \amp  \ddots \amp  \vdots\\ x_{n1} \amp  x_{n2} \amp  \cdots \amp  x_{nd} \end{bmatrix} \begin{bmatrix}u_{11}\\ u_{12}\\\vdots \\u_{1d} \end{bmatrix} =Xu_1\text{.}
\end{equation*}
</div>
</div>
<div class="para logical" id="sec10-1-PCA-3-7">
<div class="para">Next we deal with the second issue in PCA, namely, ’variance’. For this we take the centered data <span class="process-math">\(X_c =X-\overline{X}\text{,}\)</span> where <span class="process-math">\(\overline{X}=\frac{1}{d}\begin{bmatrix}x_{11}+x_{12}+\cdots+x_{1d}\\ x_{21}+x_{22}+\cdots+x_{2d}\\\vdots\\x_{1n}+x_{1n}+\cdots+x_{1n} \end{bmatrix}\text{.}\)</span> The covariance of <span class="process-math">\(X\text{,}\)</span> is given</div>
<div class="displaymath process-math">
\begin{equation*}
S ={ Cov}(X)=\frac{1}{n-1}{X_c}^TX_c\text{.}
\end{equation*}
</div>
</div>
<div class="para logical" id="sec10-1-PCA-3-8">
<div class="para">Note that (i) <span class="process-math">\(S\)</span> is symmetric and (ii) Semi-positive definite, all eigenvalues of <span class="process-math">\(S\)</span> are non negative. Also <span class="process-math">\(S\)</span> is orthogonally diagonalizable. In particular, there exists an orthogonal matrix <span class="process-math">\(U = \begin{bmatrix}u_1\amp u_2\amp \cdots \amp  u_d \end{bmatrix}\)</span> such that <span class="process-math">\(U^TSU = { diag }(\lambda_1,\cdots,\lambda_p)\text{.}\)</span> What we wanted was to maximize the variance of projection of the data onto unit vector <span class="process-math">\(u\text{.}\)</span> That is, we want to find an unit vector <span class="process-math">\(u\)</span> such that the variance of <span class="process-math">\(X_cu\)</span> is maximum. In other words,</div>
<div class="displaymath process-math" id="sec10-1-PCA-3-8-9">
\begin{align*}
\text{maximize }\amp \frac{1}{n-1}(X_cu)^T{X_cu}=\frac{1}{n-1}u^T(X_c^TX_c)u=u^TSu\\
\text{subject to } \amp  \norm{u}=1\text{.}
\end{align*}
</div>
</div>
<div class="para" id="sec10-1-PCA-3-9">It turns out that the solution of this optimization problem is <span class="process-math">\(u\text{,}\)</span> which is the eigenvector of <span class="process-math">\(S\text{.}\)</span> Thus the variance of the projected data onto a unit vector is maximum if <span class="process-math">\(u\)</span> happens to be an eigenvector of the covariance matrix <span class="process-math">\(S\text{.}\)</span>
</div>
<div class="para" id="sec10-1-PCA-3-10">Note that <span class="process-math">\(S\)</span> is of order <span class="process-math">\(d\times d\)</span> which has <span class="process-math">\(d\)</span> linearly independent eigenvectors. We arrange these eigenvector corresponding to the decreasing eigenvalues. That <span class="process-math">\(u_1\)</span> is the eigenvector corresponding to the largest eigenvector <span class="process-math">\(\lambda_1\)</span> and is called the first principal component. The eigenvector <span class="process-math">\(u_2\)</span> corresponding to the second highest eigenvalue <span class="process-math">\(\lambda_2\text{,}\)</span> is called the second principal component. Thus if we project data onto the second principal component that it will have second higher variance. Look at <a href="sec10-1-PCA.html#fig_data_pca" class="xref" data-knowl="./knowl/xref/fig_data_pca.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.7">Figure 10.1.7</a> in which the data is plotted along with the principal components. The <a href="sec10-1-PCA.html#fig_datapac_proj" class="xref" data-knowl="./knowl/xref/fig_datapac_proj.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.8">Figure 10.1.8</a>, the data projected on the 1st component of PCA is plotted along with the data.</div>
<figure class="figure figure-like" id="fig_data_pca"><div class="image-box" style="width: 45%; margin-left: 27.5%; margin-right: 27.5%;"><img src="external/images/data_pca.png" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.7<span class="period">.</span></span><span class="space"> </span>Data set with principal components</figcaption></figure><figure class="figure figure-like" id="fig_datapac_proj"><div class="image-box" style="width: 45%; margin-left: 27.5%; margin-right: 27.5%;"><img src="external/images/datapca_proj.png" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.8<span class="period">.</span></span><span class="space"> </span>Projection on 1st PCA components</figcaption></figure><div class="para logical" id="sec10-1-PCA-3-13">
<div class="para">Next question is how many principal components, we should choose. This depends upon what percentage of variance of the data we wish to capture. Suppose we want to capture 90% variations, the we choose the 1st <span class="process-math">\(k\)</span> components such that</div>
<div class="displaymath process-math">
\begin{equation*}
\frac{\sum_{i=1}^k \lambda_i}{\sum_{j=1}^d\lambda_j}\geq 0.9\text{.}
\end{equation*}
</div>
</div>
<div class="para logical" id="sec10-1-PCA-3-14">
<div class="para">The projected data onto the 1st <span class="process-math">\(k\)</span> principal components is given by</div>
<div class="displaymath process-math">
\begin{equation*}
\begin{bmatrix}x_{11} \amp  x_{12} \amp  \cdots \amp  x_{1d}\\ x_{21} \amp  x_{22} \amp  \cdots \amp  x_{2d}\\ \vdots \amp  \vdots \amp  \ddots \amp  \vdots\\ x_{n1} \amp  x_{n2} \amp  \cdots \amp  x_{nd} \end{bmatrix} \begin{bmatrix}u_1\amp u_2\amp \cdots \amp  u_k \end{bmatrix} =XV= \begin{bmatrix}z_{11} \amp  z_{12} \amp  \cdots \amp  z_{1k}\\ z_{21} \amp  z_{22} \amp  \cdots \amp  z_{2k}\\ \vdots \amp  \vdots \amp  \ddots \amp  \vdots\\ z_{n1} \amp  z_{n2} \amp  \cdots \amp  z_{nk} \end{bmatrix} =Z
\end{equation*}
</div>
</div>
<div class="para" id="sec10-1-PCA-3-15">Here <span class="process-math">\(V\)</span> is called the loading matrix. The new data or transformed data <span class="process-math">\(Z=XV\text{.}\)</span> Once we know the transformed data then we can construct the original data by <span class="process-math">\(X=ZV^T\text{.}\)</span>
</div>
<article class="example example-like" id="sec10-1-PCA-3-16"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">10.1.9</span><span class="period">.</span>
</h4>
<div class="para" id="sec10-1-PCA-3-16-1-1">Consider the following 2 dimensional data.</div> <div class="tabular-box natural-width"><table class="tabular">
<tr>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(x_1\)</span></td>
<td class="l m b0 r0 l0 t0 lines">2.5</td>
<td class="l m b0 r0 l0 t0 lines">0.5</td>
<td class="l m b0 r0 l0 t0 lines">2.2</td>
<td class="l m b0 r0 l0 t0 lines">1.9</td>
<td class="l m b0 r0 l0 t0 lines">3.0</td>
<td class="l m b0 r0 l0 t0 lines">2.3</td>
<td class="l m b0 r0 l0 t0 lines">2.0</td>
<td class="l m b0 r0 l0 t0 lines">1.0</td>
<td class="l m b0 r0 l0 t0 lines">1.5</td>
<td class="l m b0 r0 l0 t0 lines">1.1</td>
</tr>
<tr>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(x_2\)</span></td>
<td class="l m b0 r0 l0 t0 lines">2.0</td>
<td class="l m b0 r0 l0 t0 lines">0.7</td>
<td class="l m b0 r0 l0 t0 lines">2.9</td>
<td class="l m b0 r0 l0 t0 lines">2.2</td>
<td class="l m b0 r0 l0 t0 lines">2.8</td>
<td class="l m b0 r0 l0 t0 lines">2.7</td>
<td class="l m b0 r0 l0 t0 lines">1.6</td>
<td class="l m b0 r0 l0 t0 lines">1.1</td>
<td class="l m b0 r0 l0 t0 lines">1.6</td>
<td class="l m b0 r0 l0 t0 lines">0.9</td>
</tr>
</table></div> <div class="para" id="sec10-1-PCA-3-16-1-3">Find the first and the second principal components of this data set. Explain what percentage of variance os explained by the 1st principal component.</div> <div class="para logical" id="sec10-1-PCA-3-16-1-4">
<div class="para">The <span class="process-math">\(\overline{x_1} =1.8\)</span> and <span class="process-math">\(\overline{x_2}=1.85\text{.}\)</span> The centered data set is</div>
<div class="displaymath process-math">
\begin{equation*}
X_c = X - \begin{bmatrix}\overline{x_1}\\\overline{x_2} \end{bmatrix} =\left(\begin{array}{rr} 0.7 \amp  0.15 \\ -1.3 \amp  -1.15\\ 0.4 \amp  1.05\\ 0.1 \amp  0.35 \\ 1.2 \amp  0.95 \\ 0.5\amp  0.85 \\ 0.2 \amp  -0.25\\ -0.8 \amp  -0.75 \\ -0.3 \amp  -0.25 \\ -0.7 \amp  -0.95 \end{array} \right)
\end{equation*}
</div>
</div> <div class="para logical" id="sec10-1-PCA-3-16-1-5">
<div class="para">Next we construct the covariance matrix of <span class="process-math">\(X\text{,}\)</span> which is</div>
<div class="displaymath process-math">
\begin{equation*}
S = \frac{1}{10-1}X_c^TX_c=\left(\begin{array}{rr} 0.589 \amp  0.546 \\ 0.546 \amp  0.643 \end{array} \right)
\end{equation*}
</div>
</div> <div class="para" id="sec10-1-PCA-3-16-1-6">The eigenvalues of <span class="process-math">\(S\)</span> are eigenvalues <span class="process-math">\(\lambda_1 =1.1620\)</span> and <span class="process-math">\(\lambda_2=0.0696\text{.}\)</span> The corresponding eigenvectors are <span class="process-math">\(u_1 = \begin{pmatrix}0.6894\\0.7243 \end{pmatrix}\)</span> and <span class="process-math">\(u_2 = \begin{pmatrix}0.7243\\-0.689 \end{pmatrix}\text{.}\)</span>
</div> <div class="para logical" id="sec10-1-PCA-3-16-1-7">
<div class="para">Hence the loading matrix <span class="process-math">\(V\)</span> is given by</div>
<div class="displaymath process-math">
\begin{equation*}
V = \left(\begin{array}{rr} 0.6894 \amp  0.7243 \\ 0.7243 \amp  -0.6894 \end{array} \right)\text{.}
\end{equation*}
</div>
<div class="para">The projected data on the 1st two principal components is</div>
<div class="displaymath process-math">
\begin{equation*}
Z = X_cV = \left(\begin{array}{rr} 0.591 \amp  0.404 \\ -1.73 \amp  -0.149 \\ 1.04 \amp  -0.434 \\ 0.322 \amp  -0.169 \\ 1.52 \amp  0.214 \\ 0.960 \amp  -0.224 \\ -0.0432 \amp  0.317 \\ -1.09 \amp  -0.0624 \\ -0.388 \amp  -0.0449 \\ -1.17 \amp  0.148 \end{array} \right)
\end{equation*}
</div>
</div> <div class="para logical" id="sec10-1-PCA-3-16-1-8">
<div class="para">We can recover the original data set by</div>
<div class="displaymath process-math">
\begin{equation*}
ZV^T+\left(\begin{array}{rr} 1.80 \amp  1.85 \\ 1.80 \amp  1.85 \\ 1.80 \amp  1.85 \\ 1.80 \amp  1.85 \\ 1.80 \amp  1.85 \\ 1.80 \amp  1.85 \\ 1.80 \amp  1.85 \\ 1.80 \amp  1.85 \\ 1.80 \amp  1.85 \\ 1.80 \amp  1.85 \end{array} \right)=X
\end{equation*}
</div>
</div> <div class="para logical" id="sec10-1-PCA-3-16-1-9">
<div class="para">The variance explained by the 1st principal component is</div>
<div class="displaymath process-math">
\begin{equation*}
\frac{\lambda_1}{\lambda_1+\lambda_2}\approx 0.9435
\end{equation*}
</div>
</div> <div class="para" id="sec10-1-PCA-3-16-1-10">Thus approximately 94.35% variance is captured by the 1st principal component.</div></article><article class="example example-like" id="pca-eg2"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">10.1.10</span><span class="period">.</span>
</h4>
<div class="para" id="pca-eg2-1-1">Consider the following data in 3-dimension.</div> <div class="para" id="pca-eg2-1-2"><div class="tabular-box natural-width"><table class="tabular">
<tr>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(x_1\)</span></td>
<td class="l m b0 r0 l0 t0 lines">24</td>
<td class="l m b0 r0 l0 t0 lines">8</td>
<td class="l m b0 r0 l0 t0 lines">21</td>
<td class="l m b0 r0 l0 t0 lines">1</td>
<td class="l m b0 r0 l0 t0 lines">9</td>
<td class="l m b0 r0 l0 t0 lines">7</td>
<td class="l m b0 r0 l0 t0 lines">8</td>
<td class="l m b0 r0 l0 t0 lines">10</td>
<td class="l m b0 r0 l0 t0 lines">1</td>
<td class="l m b0 r0 l0 t0 lines">15</td>
<td class="l m b0 r0 l0 t0 lines">4</td>
<td class="l m b0 r0 l0 t0 lines">12</td>
</tr>
<tr>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(x_2\)</span></td>
<td class="l m b0 r0 l0 t0 lines">13</td>
<td class="l m b0 r0 l0 t0 lines">3</td>
<td class="l m b0 r0 l0 t0 lines">6</td>
<td class="l m b0 r0 l0 t0 lines">14</td>
<td class="l m b0 r0 l0 t0 lines">3</td>
<td class="l m b0 r0 l0 t0 lines">1</td>
<td class="l m b0 r0 l0 t0 lines">7</td>
<td class="l m b0 r0 l0 t0 lines">16</td>
<td class="l m b0 r0 l0 t0 lines">3</td>
<td class="l m b0 r0 l0 t0 lines">2</td>
<td class="l m b0 r0 l0 t0 lines">6</td>
<td class="l m b0 r0 l0 t0 lines">10</td>
</tr>
<tr>
<td class="l m b1 r0 l0 t0 lines"><span class="process-math">\(x_3\)</span></td>
<td class="l m b1 r0 l0 t0 lines">38</td>
<td class="l m b1 r0 l0 t0 lines">17</td>
<td class="l m b1 r0 l0 t0 lines">40</td>
<td class="l m b1 r0 l0 t0 lines">-9</td>
<td class="l m b1 r0 l0 t0 lines">21</td>
<td class="l m b1 r0 l0 t0 lines">14</td>
<td class="l m b1 r0 l0 t0 lines">11</td>
<td class="l m b1 r0 l0 t0 lines">3</td>
<td class="l m b1 r0 l0 t0 lines">2</td>
<td class="l m b1 r0 l0 t0 lines">30</td>
<td class="l m b1 r0 l0 t0 lines">1</td>
<td class="l m b1 r0 l0 t0 lines">18</td>
</tr>
<tr>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(x_1\)</span></td>
<td class="l m b0 r0 l0 t0 lines">1</td>
<td class="l m b0 r0 l0 t0 lines">7</td>
<td class="l m b0 r0 l0 t0 lines">5</td>
<td class="l m b0 r0 l0 t0 lines">1</td>
<td class="l m b0 r0 l0 t0 lines">21</td>
<td class="l m b0 r0 l0 t0 lines">8</td>
<td class="l m b0 r0 l0 t0 lines">1</td>
<td class="l m b0 r0 l0 t0 lines">15</td>
<td class="l m b0 r0 l0 t0 lines">16</td>
<td class="l m b0 r0 l0 t0 lines">7</td>
<td class="l m b0 r0 l0 t0 lines">14</td>
<td class="l m b0 r0 l0 t0 lines">3</td>
<td class="l m b0 r0 l0 t0 lines">5</td>
</tr>
<tr>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(x_2\)</span></td>
<td class="l m b0 r0 l0 t0 lines">9</td>
<td class="l m b0 r0 l0 t0 lines">3</td>
<td class="l m b0 r0 l0 t0 lines">1</td>
<td class="l m b0 r0 l0 t0 lines">12</td>
<td class="l m b0 r0 l0 t0 lines">9</td>
<td class="l m b0 r0 l0 t0 lines">8</td>
<td class="l m b0 r0 l0 t0 lines">18</td>
<td class="l m b0 r0 l0 t0 lines">8</td>
<td class="l m b0 r0 l0 t0 lines">10</td>
<td class="l m b0 r0 l0 t0 lines">0</td>
<td class="l m b0 r0 l0 t0 lines">2</td>
<td class="l m b0 r0 l0 t0 lines">7</td>
<td class="l m b0 r0 l0 t0 lines">6</td>
</tr>
<tr>
<td class="l m b0 r0 l0 t0 lines"><span class="process-math">\(x_3\)</span></td>
<td class="l m b0 r0 l0 t0 lines">-4</td>
<td class="l m b0 r0 l0 t0 lines">19</td>
<td class="l m b0 r0 l0 t0 lines">13</td>
<td class="l m b0 r0 l0 t0 lines">-6</td>
<td class="l m b0 r0 l0 t0 lines">34</td>
<td class="l m b0 r0 l0 t0 lines">7</td>
<td class="l m b0 r0 l0 t0 lines">-18</td>
<td class="l m b0 r0 l0 t0 lines">25</td>
<td class="l m b0 r0 l0 t0 lines">29</td>
<td class="l m b0 r0 l0 t0 lines">17</td>
<td class="l m b0 r0 l0 t0 lines">31</td>
<td class="l m b0 r0 l0 t0 lines">0</td>
<td class="l m b0 r0 l0 t0 lines">7</td>
</tr>
</table></div></div> <div class="para logical" id="pca-eg2-1-3">
<div class="para">The mean of each feature are <span class="process-math">\(\overline{x_1}=8.96, \overline{x_2}=7.081,\overline{x_2}=3.6\text{.}\)</span> We have</div>
<div class="displaymath process-math">
\begin{equation*}
X= \left(\begin{array}{rrr} 24 \amp  13 \amp  38 \\ 8 \amp  3 \amp  17 \\\vdots \amp  \vdots \amp  \vdots \\ 5 \amp  6 \amp  7 \end{array} \right), X -\overline{X} = \left(\begin{array}{rrr} 15.04 \amp  5.92 \amp  24.4 \\ -0.96 \amp  -4.08 \amp  3.4 \\\vdots \amp  \vdots \amp \vdots\\ -3.96 \amp  -1.08 \amp  -6.6 \end{array} \right)
\end{equation*}
</div>
</div> <div class="para logical" id="pca-eg2-1-4">
<div class="para">The covariance matrix of <span class="process-math">\(X\)</span> is given by</div>
<div class="displaymath process-math" id="pca-eg2-1-4-2">
\begin{align*}
{ Cov}(X)=S=\amp \frac{1}{n-1}(X -\overline{X})^T(X -\overline{X})\\
=\amp \left(\begin{array}{rrr} 45.7066 \amp  -0.2466\amp  94.8583 \\ -0.2466 \amp  24.0766 \amp  -29.175 \\ 94.8583\amp  -29.175 \amp  235.9166 \end{array} \right)
\end{align*}
</div>
</div> <div class="para logical" id="pca-eg2-1-5">
<div class="para">The eigenvalues of <span class="process-math">\(S\)</span> are <span class="process-math">\(\lambda_1=278.02366293, \lambda_2=26.95307696, \lambda_3=0.72326011\text{.}\)</span> The corresponding eigenvectors are</div>
<div class="displaymath process-math">
\begin{equation*}
pc_1=\left(\begin{array}{r} 0.3759787 \\ -0.10612 \\ 0.920531 \end{array} \right), pc_2=\left(\begin{array}{r} 0.46959\\ 0.87822 \\ -0.09055 \end{array} \right), pc_3=\left(\begin{array}{r} 0.79882 \\ -0.4663\\ -0.38003 \end{array} \right)\text{.}
\end{equation*}
</div>
</div> <div class="para logical" id="pca-eg2-1-6">
<div class="para">The percentage of variance explained by the first principal component is</div>
<div class="displaymath process-math">
\begin{equation*}
\frac{\lambda_1}{\lambda_1+\lambda_2+\lambda_3}\approx 0.9094\approx  90.94%
\end{equation*}
</div>
</div> The percentage of variance explained by the first two principal components is <div class="para logical" id="pca-eg2-1-7"><div class="displaymath process-math">
\begin{equation*}
\frac{\lambda_1+\lambda_2}{\lambda_1+\lambda_2+\lambda_3}\approx 0.997=99.7%
\end{equation*}
</div></div></article></section><section class="subsection" id="sec10-1-PCA-4"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">10.1.2</span><span class="space"> </span><span class="title">Applications of PCA</span>
</h3>
<div class="para" id="sec10-1-PCA-4-2">PC, as mentioned earlier, is a dimensionality reduction techniques. It has numerous applications like, visualization of high dimensional data, facial recognition, computer vision, image compression, determining patterns in a data, data mining, bioinformatics, psychology, analyzing and forecasting stock data,etc.</div>
<div class="para" id="sec10-1-PCA-4-3">We mention, image compression as one of the applications.</div></section><section class="subsection" id="sec10-1-PCA-5"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">10.1.3</span><span class="space"> </span><span class="title">Image compression with PCA</span>
</h3>
<div class="para" id="sec10-1-PCA-5-2">Similar to SVD, we can also compress the images using PCA. We take any image, first of all we separate the RBG channels of the images and apply PCA separately to red channel, green channel and blue channel. Next we take first <span class="process-math">\(k\)</span> principal components and project the red, green and blue channel images and then combine the three channels to obtained the transformed image with <span class="process-math">\(k\)</span> principal components.</div>
<article class="example example-like" id="sec10-1-PCA-5-3"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">10.1.11</span><span class="period">.</span>
</h4>
<div class="para" id="sec10-1-PCA-5-3-1-1">Consider an image of a Rose as shown in the <a href="sec10-1-PCA.html#fig_Rose" class="xref" data-knowl="./knowl/xref/fig_Rose.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.12">Figure 10.1.12</a> This image is of sinze <span class="process-math">\(600\times 800\times 3\)</span> array.</div> <figure class="figure figure-like" id="fig_Rose"><div class="image-box" style="width: 50%; margin-left: 25%; margin-right: 25%;"><img src="external/images/Rose.png" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.12<span class="period">.</span></span><span class="space"> </span>Original  Rose Image</figcaption></figure> <div class="para" id="sec10-1-PCA-5-3-1-3">The red green and blue channel images are shown in the <a href="sec10-1-PCA.html#fig_RoseR" class="xref" data-knowl="./knowl/xref/fig_RoseR.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.13">Figures 10.1.13</a>, <a href="sec10-1-PCA.html#fig_RoseG" class="xref" data-knowl="./knowl/xref/fig_RoseG.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.14">Figure 10.1.14</a>, <a href="sec10-1-PCA.html#fig_RoseB" class="xref" data-knowl="./knowl/xref/fig_RoseB.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.15">Figure 10.1.15</a>.</div> <figure class="figure figure-like" id="fig_RoseR"><div class="image-box" style="width: 33%; margin-left: 33.5%; margin-right: 33.5%;"><img src="external/images/RoseR.png" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.13<span class="period">.</span></span><span class="space"> </span>Red Channel</figcaption></figure> <figure class="figure figure-like" id="fig_RoseG"><div class="image-box" style="width: 33%; margin-left: 33.5%; margin-right: 33.5%;"><img src="external/images/RoseR.png" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.14<span class="period">.</span></span><span class="space"> </span>Green Channel</figcaption></figure> <figure class="figure figure-like" id="fig_RoseB"><div class="image-box" style="width: 33%; margin-left: 33.5%; margin-right: 33.5%;"><img src="external/images/RoseR.png" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.15<span class="period">.</span></span><span class="space"> </span>Blue Channel</figcaption></figure> <div class="para" id="sec10-1-PCA-5-3-1-7">After applying PCA and taking first 5, 20 and 50 principal components and combining the three channels together we get the following approximate images as shown in the <a href="sec10-1-PCA.html#fig_Rose-PCA5" class="xref" data-knowl="./knowl/xref/fig_Rose-PCA5.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.16">Figures 10.1.16</a>, <a href="sec10-1-PCA.html#fig_Rose-PCA20" class="xref" data-knowl="./knowl/xref/fig_Rose-PCA20.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.17">Figure 10.1.17</a>, <a href="sec10-1-PCA.html#fig_Rose-PCA50" class="xref" data-knowl="./knowl/xref/fig_Rose-PCA50.html" data-reveal-label="Reveal" data-close-label="Close" title="Figure 10.1.18">Figure 10.1.18</a>, respectively. Each channel is of size <span class="process-math">\(600\times 800\text{.}\)</span>
</div> <figure class="figure figure-like" id="fig_Rose-PCA5"><div class="image-box" style="width: 33%; margin-left: 33.5%; margin-right: 33.5%;"><img src="external/images/Rose_PCA5.png" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.16<span class="period">.</span></span><span class="space"> </span>5 components</figcaption></figure> <figure class="figure figure-like" id="fig_Rose-PCA20"><div class="image-box" style="width: 33%; margin-left: 33.5%; margin-right: 33.5%;"><img src="external/images/Rose_PCA20.png" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.17<span class="period">.</span></span><span class="space"> </span>20 components</figcaption></figure> <figure class="figure figure-like" id="fig_Rose-PCA50"><div class="image-box" style="width: 33%; margin-left: 33.5%; margin-right: 33.5%;"><img src="external/images/Rose_PCA50.png" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">10.1.18<span class="period">.</span></span><span class="space"> </span>50 components</figcaption></figure> <div class="para" id="sec10-1-PCA-5-3-1-11">We can see from the image, that 1st 50 components gives a very good approximation to the original image.</div></article></section><section class="subsection" id="sec10-1-PCA-6"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">10.1.4</span><span class="space"> </span><span class="title">Relation Between SVD and PCA</span>
</h3>
<div class="para logical" id="sec10-1-PCA-6-2">
<div class="para">Consider a matrix <span class="process-math">\(X\)</span> of size <span class="process-math">\(n\times d\text{.}\)</span> We can apply SVD and PCA on <span class="process-math">\(X\text{.}\)</span> Suppose the SVD of <span class="process-math">\(X\)</span> is given by</div>
<div class="displaymath process-math">
\begin{equation*}
X = U\Sigma V^T\text{.}
\end{equation*}
</div>
<div class="para">Let <span class="process-math">\(U=[u_1~\ldots~ u_n]\)</span> and <span class="process-math">\(V^T=\begin{bmatrix}v_1^T\\v_2^T\\\vdots\\v_d^T \end{bmatrix}\text{.}\)</span> Then</div>
<div class="displaymath process-math">
\begin{equation*}
X^TX = V\left( \Sigma^T\Sigma\right) V^T\text{.}
\end{equation*}
</div>
</div>
<div class="para logical" id="sec10-1-PCA-6-3">
<div class="para">The covariance matrix of <span class="process-math">\(X\)</span> is <span class="process-math">\(\frac{1}{n-1}X^TX\text{.}\)</span> This shows that <span class="process-math">\(S\)</span> and <span class="process-math">\(X^TX\)</span> are similar matrices. If <span class="process-math">\(\lambda_1,\ldots, \lambda_r\)</span> are non zero eigenvalues of <span class="process-math">\(S\)</span> and <span class="process-math">\(\sigma_1,\ldots, \sigma_r\)</span> are singular values of <span class="process-math">\(X\text{.}\)</span> Then they are related by the following relation</div>
<div class="displaymath process-math">
\begin{equation*}
\sigma_i^2=(n-1)\lambda_i, i = 1, 2,\ldots, r\text{.}
\end{equation*}
</div>
</div>
<div class="para logical" id="sec10-1-PCA-6-4">
<div class="para">The relation <span class="process-math">\(X^TX = V\left( \Sigma^T\Sigma\right) V^T\)</span> shows that right singular vectors are same as principal components. The left singular vectors are given by</div>
<div class="displaymath process-math">
\begin{equation*}
u_i = \frac{1}{\sqrt{n-1}}Xv_i\text{.}
\end{equation*}
</div>
</div></section><section class="subsection" id="sec10-1-PCA-7"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">10.1.5</span><span class="space"> </span><span class="title">Exercise Set</span>
</h3>
<article class="exercise exercise-like" id="sec10-1-PCA-7-2"><h4 class="heading">
<span class="type">Checkpoint</span><span class="space"> </span><span class="codenumber">10.1.19</span><span class="period">.</span>
</h4>
<div class="para" id="sec10-1-PCA-7-2-1-1">Find the singular values Decomposition of the following matrices.</div> <div class="para" id="sec10-1-PCA-7-2-1-2">(a) <span class="process-math">\(\begin{bmatrix}-2 \amp 2 \\ 1 \amp 1 \end{bmatrix}\text{,}\)</span>(b) <span class="process-math">\(\begin{bmatrix}1 \amp 1 \\ 0 \amp 1 \\1 \amp 0 \end{bmatrix}\text{,}\)</span> (c) <span class="process-math">\(\begin{bmatrix}-1 \amp 1 \\ -1 \amp 1\\2 \amp -2 \end{bmatrix}\text{,}\)</span> (d) <span class="process-math">\(\begin{bmatrix}1 \amp 1 \\ -3 \amp -3 \end{bmatrix}\text{,}\)</span> (e) <span class="process-math">\(\begin{bmatrix}1 \amp -1 \amp 0 \\ 0 \amp 0 \amp 1\\-1 \amp 1\amp 0 \end{bmatrix}\)</span>
</div></article><article class="exercise exercise-like" id="sec10-1-PCA-7-3"><h4 class="heading">
<span class="type">Checkpoint</span><span class="space"> </span><span class="codenumber">10.1.20</span><span class="period">.</span>
</h4>
<div class="para" id="sec10-1-PCA-7-3-1-1">Use SVD to find generalized inverse of the following matrices:</div> <div class="para" id="sec10-1-PCA-7-3-1-2">(a) <span class="process-math">\(\begin{bmatrix}1 \amp 1 \\ -3 \amp -3 \end{bmatrix}\text{,}\)</span> (b) <span class="process-math">\(\begin{bmatrix}1 \amp -1 \amp 0 \\ 0 \amp 0 \amp 1\\-1 \amp 1\amp 0 \end{bmatrix}\text{,}\)</span> (c) <span class="process-math">\(\begin{bmatrix}1 \amp 0 \amp -1\\-1 \amp 0 \amp 1\\0 \amp 1 \amp 0 \end{bmatrix}\text{.}\)</span>
</div></article><article class="exercise exercise-like" id="sec10-1-PCA-7-4"><h4 class="heading">
<span class="type">Checkpoint</span><span class="space"> </span><span class="codenumber">10.1.21</span><span class="period">.</span>
</h4>
<div class="para logical" id="sec10-1-PCA-7-4-1-1">
<div class="para">Use the generalized inverse from the SVD to find the least square solution of the system of linear equations <span class="process-math">\(Ax=b\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
\begin{bmatrix}1 \amp  2 \\ -1 \amp  1\\ 2 \amp  1\\ 2 \amp  -1\\1 \amp  1 \end{bmatrix} ,  b=\begin{bmatrix}2 \amp  1 \amp  -2 \amp  1 \amp  3 \end{bmatrix}\text{.}
\end{equation*}
</div>
</div></article><article class="exercise exercise-like" id="sec10-1-PCA-7-5"><h4 class="heading">
<span class="type">Checkpoint</span><span class="space"> </span><span class="codenumber">10.1.22</span><span class="period">.</span>
</h4>
<div class="para logical" id="sec10-1-PCA-7-5-1-1">
<div class="para">Find the principal components of the matrix</div>
<div class="displaymath process-math">
\begin{equation*}
\begin{bmatrix}3 \amp  -4 \amp  7 \amp  1 \amp  -4 \amp  -3\\7 \amp  -6 \amp  8 \amp  -1 \amp  -1 \amp  7 \end{bmatrix}
\end{equation*}
</div>
</div> <div class="para" id="sec10-1-PCA-7-5-1-2">What percentage of the variation in the data is explained by the first principal component.</div></article></section></section></div>
<div class="ptx-content-footer">
<a class="previous-button button" href="chap10-PCA.html" title="Previous"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cb;</span><span class="name">Prev</span></a><a class="top-button button" href="#" title="Top"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5ce;</span><span class="name">Top</span></a><a class="next-button button" href="backmatter.html" title="Next"><span class="name">Next</span><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cc;</span></a>
</div></main>
</div>
<div id="ptx-page-footer" class="ptx-page-footer">
<a class="pretext-link" href="https://pretextbook.org" title="PreTeXt"><div class="logo"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="338 3000 8772 6866"><g style="stroke-width:.025in; stroke:black; fill:none"><polyline points="472,3590 472,9732 " style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,9448 A 4660 4660  0  0  1  8598  9259"></path><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4488,9685 A 4228 4228  0  0  0   472  9732"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,3590 A 4241 4241  0  0  1  8598  3496"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,3496  A 4241 4241  0  0  1  4724  3590"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,9259  A 4507 4507  0  0  1  4724  9448"></path><polyline points="5385,4299 4062,8125" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8598,3496 8598,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="850,3496 850,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="4960,9685 4488,9685" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="3070,4582 1889,6141 3070,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="6418,4582 7600,6141 6418,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8976,3590 8976,9732" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4960,9685 A 4228 4228  0  0  1  8976  9732"></path></g></svg></div></a><a class="runestone-link" href="https://runestone.academy" title="Runestone Academy"><img class="logo" src="https://runestone.academy/runestone/static/images/RAIcon_cropped.png"></a><a class="mathjax-link" href="https://www.mathjax.org" title="MathJax"><img class="logo" src="https://www.mathjax.org/badge/badge-square-2.png"></a>
</div>
</body>
</html>
